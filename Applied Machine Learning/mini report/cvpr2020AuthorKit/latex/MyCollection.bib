@article{Yao2020,
abstract = {The recent outbreak of the coronavirus disease-2019 (COVID-19) caused serious challenges to the human society in China and across the world. COVID-19 induced pneumonia in human hosts and carried a highly inter-person contagiousness. The COVID-19 patients may carry severe symptoms, and some of them may even die of major organ failures. This study utilized the machine learning algorithms to build the COVID-19 severeness detection model. Support vector machine (SVM) demonstrated a promising detection accuracy after 32 features were detected to be significantly associated with the COVID-19 severeness. These 32 features were further screened for inter-feature redundancies. The final SVM model was trained using 28 features and achieved the overall accuracy 0.8148. This work may facilitate the risk estimation of whether the COVID-19 patients would develop the severe symptoms. The 28 COVID-19 severeness associated biomarkers may also be investigated for their underlining mechanisms how they were involved in the COVID-19 infections.},
author = {Yao, Haochen and Zhang, Nan and Zhang, Ruochi and Duan, Meiyu and Xie, Tianqi and Pan, Jiahui and Peng, Ejun and Huang, Juanjuan and Zhang, Yingli and Xu, Xiaoming and Xu, Hong and Zhou, Fengfeng and Wang, Guoqing},
doi = {10.3389/fcell.2020.00683},
file = {:home/roasted{\_}kernel/Downloads/fcell-08-00683.pdf:pdf},
issn = {2296634X},
journal = {Frontiers in Cell and Developmental Biology},
keywords = {COVID-19,biomarkers,blood and urine tests,model,severity detection},
number = {July},
pages = {1--10},
title = {{Severity Detection for the Coronavirus Disease 2019 (COVID-19) Patients Using a Machine Learning Model Based on the Blood and Urine Tests}},
volume = {8},
year = {2020}
}
@article{Noe2020,
abstract = {Many aspects of the study of protein folding and dynamics have been affected by the recent advances in machine learning. Methods for the prediction of protein structures from their sequences are now heavily based on machine learning tools. The way simulations are performed to explore the energy landscape of protein systems is also changing as force-fields are started to be designed by means of machine learning methods. These methods are also used to extract the essential information from large simulation datasets and to enhance the sampling of rare events such as folding/unfolding transitions. While significant challenges still need to be tackled, we expect these methods to play an important role on the study of protein folding and dynamics in the near future. We discuss here the recent advances on all these fronts and the questions that need to be addressed for machine learning approaches to become mainstream in protein simulation.},
archivePrefix = {arXiv},
arxivId = {1911.09811},
author = {No{\'{e}}, Frank and {De Fabritiis}, Gianni and Clementi, Cecilia},
doi = {10.1016/j.sbi.2019.12.005},
eprint = {1911.09811},
file = {:home/roasted{\_}kernel/Downloads/10.1016@j.sbi.2019.12.005.pdf:pdf},
issn = {1879033X},
journal = {Current Opinion in Structural Biology},
pages = {77--84},
pmid = {31881449},
publisher = {Elsevier Ltd},
title = {{Machine learning for protein folding and dynamics}},
url = {https://doi.org/10.1016/j.sbi.2019.12.005},
volume = {60},
year = {2020}
}
@article{Toropov2011,
abstract = {Optimal descriptors calculated with simplified molecular input line entry system (SMILES), hydrogen-suppressed molecular graph (HSG), hydrogen-filled molecular graph (HFG), and graph of atomic orbitals (GAO) have been studied as a basis to build up models for mutagenicity of polyaromatic amines. The optimal descriptors are calculated with correlation weights of the molecular fragments. In the case of the molecular graph, chemical elements (C, N, O, etc.) or their electronic structure (1s2, 2p3, 3d10, etc.) together with their Morgan vertex degrees are the basis for calculation of the descriptor. In the case of SMILES, chemical elements (C, O, N, etc.) together with presence of cycles (1, 2, 3, etc.), cis-, trans- isomerism ('$\backslash$' and '/') and other are the basis for calculation of the descriptor. In both these cases, descriptors are a mathematical function of the correlation weights of the above-mentioned molecular features. The correlation weights are calculated by the Monte Carlo optimization (the target function is the correlation coefficient between experimental and predicted endpoint values). SMILES-based optimal descriptors have shown the preferable predictive ability. The CORAL software (http://www.insilico.eu/coral/) was used to build up models of the mutagenic potential as the function of the molecular structure. Analysis of three probes of the Monte Carlo optimization with six random splits has shown there are three kinds of the molecular features encoded by SMILES attributes: promoters of increase/decrease of mutagenic potential and ones without defined role. {\textcopyright} 2011 Elsevier B.V.},
author = {Toropov, A. A. and Toropova, A. P. and Martyanov, S. E. and Benfenati, E. and Gini, G. and Leszczynska, D. and Leszczynski, J.},
doi = {10.1016/j.chemolab.2011.07.008},
file = {:home/roasted{\_}kernel/Downloads/toropov2011.pdf:pdf},
issn = {01697439},
journal = {Chemometrics and Intelligent Laboratory Systems},
keywords = {Monte Carlo method,Mutagenicity,Optimal descriptor,QSAR},
number = {1},
pages = {94--100},
publisher = {Elsevier B.V.},
title = {{Comparison of SMILES and molecular graphs as the representation of the molecular structure for QSAR analysis for mutagenic potential of polyaromatic amines}},
url = {http://dx.doi.org/10.1016/j.chemolab.2011.07.008},
volume = {109},
year = {2011}
}
@article{Hamilton2017,
abstract = {Low-dimensional embeddings of nodes in large graphs have proved extremely useful in a variety of prediction tasks, from content recommendation to identifying protein functions. However, most existing approaches require that all nodes in the graph are present during training of the embeddings; these previous approaches are inherently transductive and do not naturally generalize to unseen nodes. Here we present GraphSAGE, a general inductive framework that leverages node feature information (e.g., text attributes) to efficiently generate node embeddings for previously unseen data. Instead of training individual embeddings for each node, we learn a function that generates embeddings by sampling and aggregating features from a node's local neighborhood. Our algorithm outperforms strong baselines on three inductive node-classification benchmarks: we classify the category of unseen nodes in evolving information graphs based on citation and Reddit post data, and we show that our algorithm generalizes to completely unseen graphs using a multi-graph dataset of protein-protein interactions.},
archivePrefix = {arXiv},
arxivId = {1706.02216},
author = {Hamilton, William L. and Ying, Rex and Leskovec, Jure},
eprint = {1706.02216},
file = {:home/roasted{\_}kernel/Downloads/1706.02216.pdf:pdf},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
number = {Nips},
pages = {1025--1035},
title = {{Inductive representation learning on large graphs}},
volume = {2017-December},
year = {2017}
}
@article{Kipf2017,
abstract = {We present a scalable approach for semi-supervised learning on graph-structured data that is based on an efficient variant of convolutional neural networks which operate directly on graphs. We motivate the choice of our convolutional architecture via a localized first-order approximation of spectral graph convolutions. Our model scales linearly in the number of graph edges and learns hidden layer representations that encode both local graph structure and features of nodes. In a number of experiments on citation networks and on a knowledge graph dataset we demonstrate that our approach outperforms related methods by a significant margin.},
archivePrefix = {arXiv},
arxivId = {1609.02907},
author = {Kipf, Thomas N. and Welling, Max},
eprint = {1609.02907},
file = {:home/roasted{\_}kernel/Downloads/1609.02907.pdf:pdf},
journal = {5th International Conference on Learning Representations, ICLR 2017 - Conference Track Proceedings},
pages = {1--14},
title = {{Semi-supervised classification with graph convolutional networks}},
year = {2017}
}
@article{Feinberg2018,
abstract = {The arc of drug discovery entails a multiparameter optimization problem spanning vast length scales. The key parameters range from solubility (angstroms) to protein-ligand binding (nanometers) to in vivo toxicity (meters). Through feature learning - instead of feature engineering - deep neural networks promise to outperform both traditional physics-based and knowledge-based machine learning models for predicting molecular properties pertinent to drug discovery. To this end, we present the PotentialNet family of graph convolutions. These models are specifically designed for and achieve state-of-the-art performance for protein-ligand binding affinity. We further validate these deep neural networks by setting new standards of performance in several ligand-based tasks. In parallel, we introduce a new metric, the Regression Enrichment Factor EF$\chi$(R), to measure the early enrichment of computational models for chemical data. Finally, we introduce a cross-validation strategy based on structural homology clustering that can more accurately measure model generalizability, which crucially distinguishes the aims of machine learning for drug discovery from standard machine learning tasks.},
archivePrefix = {arXiv},
arxivId = {1803.04465},
author = {Feinberg, Evan N. and Sur, Debnil and Wu, Zhenqin and Husic, Brooke E. and Mai, Huanghao and Li, Yang and Sun, Saisai and Yang, Jianyi and Ramsundar, Bharath and Pande, Vijay S.},
doi = {10.1021/acscentsci.8b00507},
eprint = {1803.04465},
file = {:home/roasted{\_}kernel/Downloads/acscentsci.8b00507.pdf:pdf},
issn = {23747951},
journal = {ACS Central Science},
number = {11},
pages = {1520--1530},
pmid = {30555904},
title = {{PotentialNet for Molecular Property Prediction}},
volume = {4},
year = {2018}
}
@article{Gilmer2017,
abstract = {Supervised learning on molecules has incredible potential to be useful in chemistry, drug discovery, and materials science. Luckily, several promising and closely related neural network models invariant to molecular symmetries have already been described in the literature. These models learn a message passing algorithm and aggregation procedure to compute a function of their entire input graph. At this point, the next step is to find a particularly effective variant of this general approach and apply it to chemical prediction benchmarks until we either solve them or reach the limits of the approach. In this paper, we reformulate existing models into a single common framework we call Message Passing Neural Networks (MPNNs) and explore additional novel variations within this framework. Using MPNNs we demonstrate state of the art results on an important molecular property prediction benchmark; these results are strong enough that we believe future work should focus on datasets with larger molecules or more accurate ground truth labels.},
archivePrefix = {arXiv},
arxivId = {1704.01212},
author = {Gilmer, Justin and Schoenholz, Samuel S. and Riley, Patrick F. and Vinyals, Oriol and Dahl, George E.},
eprint = {1704.01212},
file = {:home/roasted{\_}kernel/Downloads/1704.01212.pdf:pdf},
isbn = {9781510855144},
journal = {34th International Conference on Machine Learning, ICML 2017},
pages = {2053--2070},
title = {{Neural message passing for quantum chemistry}},
volume = {3},
year = {2017}
}
