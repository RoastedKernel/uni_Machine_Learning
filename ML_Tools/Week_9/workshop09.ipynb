{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workshop 9 - Introduction to Convolutional Neural Networks\n",
    "\n",
    "Code for workshop 9.  This will use Keras (within tensorflow v2) to build a small CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os, time\n",
    "import pandas as pd\n",
    "\n",
    "# Deep Learning imports\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# To plot nice figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "import seaborn as sns; sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n",
      "2.3.0-tf\n"
     ]
    }
   ],
   "source": [
    "# Check the versions are OK (both should be 2 or more)\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "We will use fashion MNIST, which is a set of small images (28x28) that contain 10 different fashion items - see below for class names and an example image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a built-in data for keras, so easily accessible\n",
    "mnist = keras.datasets.mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Let's see how big it is\n",
    "print(X_train_full.shape)\n",
    "print(X_test.shape)\n",
    "n_total = X_train_full.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "float64\n",
      "7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Scale the data appropriately (it starts with max of 255, but we want max of 1)\n",
    "# We will do this \"by hand\" here, but we could build a pipeline scaler for this instead\n",
    "# We also split the training set given to us into training and validation subsets\n",
    "#   The value of 5000 samples as the size of the validation set is an arbitrary choice\n",
    "X_test = X_test/255.0\n",
    "X_valid, X_train = X_train_full[:5000]/255.0, X_train_full[5000:]/255.0 \n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "class_names = np.array([ \"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\" ])\n",
    "\n",
    "# Inspect some aspects of the data (in general, you should play around with the data \n",
    "#                                   more than this to get a feel for it)\n",
    "# Check that scaled types are appropriate\n",
    "print(X_train.dtype)\n",
    "print(X_valid.dtype)\n",
    "# Look at first item\n",
    "print(class_names[y_train[0]])\n",
    "plt.imshow(X_train[0,:,:], cmap='gray')\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's look at the distribution of labels in the training, validation and test sets\n",
    "plt.hist(y_train)\n",
    "plt.show()\n",
    "plt.hist(y_valid)\n",
    "plt.show()\n",
    "plt.hist(y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Neural Network Code with Keras\n",
    "\n",
    "We will use the keras version built into tensorflow version 2.\n",
    "It is remarkably simple for building, training and evaluating networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some key parameters\n",
    "n_train = 3000\n",
    "n_valid = 1000\n",
    "# Define the number and size of hidden layers\n",
    "hiddensizes = [16, 32, 16]\n",
    "# Define the activation function to be used by hidden layers\n",
    "actfn = \"relu\"\n",
    "# Optimiser and learning rate\n",
    "optimizer = keras.optimizers.SGD\n",
    "learningrate = 0.01   # SGD default value\n",
    "# Set size of batch and number of epochs\n",
    "batch_size = 32\n",
    "n_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a CNN\n",
    "def model_cnn_factory(hiddensizes, actfn, optimizer, learningrate):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Conv2D(filters=hiddensizes[0], kernel_size=3, strides=1, activation=actfn, padding=\"same\", \n",
    "                                  input_shape=[28, 28, 1]))    # input layer goes into this 2D convolution\n",
    "    model.add(keras.layers.MaxPooling2D(pool_size=2))          # Pool (downsize)\n",
    "    for n in hiddensizes[1:-1]:\n",
    "        model.add(keras.layers.Conv2D(filters=n, kernel_size=3, strides=1, padding=\"same\", activation=actfn))  # 2nd Conv\n",
    "        model.add(keras.layers.MaxPooling2D(pool_size=2))          # Pool (downsize)\n",
    "    model.add(keras.layers.Conv2D(filters=hiddensizes[-1], kernel_size=3, strides=1, padding=\"same\", activation=actfn))  # 2nd Conv\n",
    "    model.add(keras.layers.Flatten())                          # unravel into a 1D vector\n",
    "    model.add(keras.layers.Dense(10, activation = \"softmax\"))  # always have 10 classes\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer(lr=learningrate), metrics=[\"accuracy\"])   \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional aside: the CNN can become a Fully Convolutional Network (FCN) by replacing the Flatten and Dense lines with\n",
    "#   model.add(keras.layers.Conv2D(filters=10, kernel_size=7, padding=\"valid\", activation=\"softmax\"))\n",
    "# This uses a kernel equal to the full image size (at this point) to generate a single output per filter \n",
    "#  which requires the convolution to be \"valid\" and not \"same\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_dense_factory(hiddensizes, actfn, optimizer, learningrate):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Flatten(input_shape = [28, 28, 1]))    # always have same sized inputs\n",
    "    for n in hiddensizes:\n",
    "        model.add(keras.layers.Dense(n, activation = actfn))\n",
    "    model.add(keras.layers.Dense(10, activation = \"softmax\"))   # always have 10 classes\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer(lr=learningrate), metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the data to be shape [Nx, Ny, 1]  (previously 2D was fine, but for CNN we need depth too)\n",
    "X_train = X_train.reshape((-1, 28, 28, 1))\n",
    "X_valid = X_valid.reshape((-1, 28, 28, 1))\n",
    "X_test = X_test.reshape((-1, 28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping callback - this is executed when fitting and will stop and restore best result\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_all(hiddensizes, actfn, optimizer, learningrate, n_train, n_valid, n_epochs, batch_size):\n",
    "    model = model_cnn_factory(hiddensizes, actfn, optimizer, learningrate)\n",
    "    history = model.fit(X_train[:n_train,:,:,:], y_train[:n_train], epochs=n_epochs, callbacks = [early_stopping_cb],\n",
    "                        validation_data=(X_valid[:n_valid,:,:,:], y_valid[:n_valid]))\n",
    "    max_val_acc = np.max(history.history['val_accuracy'])\n",
    "    testres = model.evaluate(X_test, y_test, verbose=0)\n",
    "    return (max_val_acc, testres[1], history, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 2.2585 - accuracy: 0.1697 - val_loss: 2.1948 - val_accuracy: 0.2000\n",
      "Epoch 2/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.9968 - accuracy: 0.4060 - val_loss: 1.6080 - val_accuracy: 0.6200\n",
      "Epoch 3/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.0628 - accuracy: 0.6987 - val_loss: 0.7274 - val_accuracy: 0.7850\n",
      "Epoch 4/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6152 - accuracy: 0.8013 - val_loss: 0.5861 - val_accuracy: 0.8160\n",
      "Epoch 5/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4843 - accuracy: 0.8417 - val_loss: 0.4967 - val_accuracy: 0.8580\n",
      "Epoch 6/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4205 - accuracy: 0.8653 - val_loss: 0.4729 - val_accuracy: 0.8560\n",
      "Epoch 7/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.3694 - accuracy: 0.8830 - val_loss: 0.4629 - val_accuracy: 0.8700\n",
      "Epoch 8/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.3384 - accuracy: 0.8960 - val_loss: 0.4229 - val_accuracy: 0.8780\n",
      "Epoch 9/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.3079 - accuracy: 0.9040 - val_loss: 0.4163 - val_accuracy: 0.8620\n",
      "Epoch 10/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.2868 - accuracy: 0.9113 - val_loss: 0.3736 - val_accuracy: 0.8880\n",
      "Epoch 11/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.2705 - accuracy: 0.9203 - val_loss: 0.3363 - val_accuracy: 0.9040\n",
      "Epoch 12/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.2464 - accuracy: 0.9257 - val_loss: 0.3488 - val_accuracy: 0.9030\n",
      "Epoch 13/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.2367 - accuracy: 0.9283 - val_loss: 0.3353 - val_accuracy: 0.9050\n",
      "Epoch 14/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.2213 - accuracy: 0.9320 - val_loss: 0.3674 - val_accuracy: 0.8980\n",
      "Epoch 15/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.2099 - accuracy: 0.9383 - val_loss: 0.2948 - val_accuracy: 0.9120\n",
      "Epoch 16/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1967 - accuracy: 0.9437 - val_loss: 0.2880 - val_accuracy: 0.9190\n",
      "Epoch 17/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1875 - accuracy: 0.9457 - val_loss: 0.3356 - val_accuracy: 0.9060\n",
      "Epoch 18/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1775 - accuracy: 0.9497 - val_loss: 0.2966 - val_accuracy: 0.9160\n",
      "Epoch 19/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1733 - accuracy: 0.9477 - val_loss: 0.2744 - val_accuracy: 0.9250\n",
      "Epoch 20/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1616 - accuracy: 0.9540 - val_loss: 0.2584 - val_accuracy: 0.9270\n"
     ]
    }
   ],
   "source": [
    "valacc, testacc, history, model = do_all(hiddensizes, actfn, optimizer, learningrate, n_train, n_valid, n_epochs, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    # Plot the results (shifting validation curves appropriately)\n",
    "    plt.figure(figsize=(8,5))\n",
    "    n = len(history.history['accuracy'])\n",
    "    plt.plot(np.arange(0,n),history.history['accuracy'], color='orange')\n",
    "    plt.plot(np.arange(0,n),history.history['loss'],'b')\n",
    "    plt.plot(np.arange(0,n)+0.5,history.history['val_accuracy'],'r')  # offset both validation curves\n",
    "    plt.plot(np.arange(0,n)+0.5,history.history['val_loss'],'g')\n",
    "    plt.legend(['Train Acc','Train Loss','Val Acc','Val Loss'])\n",
    "    plt.grid(True)\n",
    "    plt.gca().set_ylim(0, 1) # set the vertical range to [0-1] \n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-18-1a22d725ee02>:2: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "[7 2 1]\n",
      "['7' '2' '1']\n",
      "['7' '2' '1']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We can inspect the output class predictions\n",
    "y_pred = model.predict_classes(X_test[:3])  # use the first three test cases as an example\n",
    "print(y_pred)   # predicted classes\n",
    "print(class_names[y_pred])   # names of these classes (prediction)\n",
    "print(class_names[y_test[:3]])   # names of true classes\n",
    "# Display an image of the first test sample\n",
    "plt.imshow(X_test[0].reshape((28,28)), cmap=\"gray\")\n",
    "plt.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2313007265329361, 0.9326000213623047]\n"
     ]
    }
   ],
   "source": [
    "# Now run the model on the test set and get results (loss and accuracy both reported)\n",
    "testres = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(testres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.   0.   0.   0.   0.   0.   0.   1.   0.   0.  ]\n",
      " [0.   0.   1.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.99 0.   0.   0.   0.   0.   0.   0.   0.  ]]\n"
     ]
    }
   ],
   "source": [
    "# We can also look at the probability of predicting each class rather than the class with max probability\n",
    "# Each row has ten probabilities (one per class)\n",
    "y_proba = model.predict(X_test[:3])\n",
    "print(y_proba.round(2))  # round to two decimal places when printing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring parameters\n",
    "\n",
    "For example, why make these particular choices for architecture and parameters.\n",
    "\n",
    "Let us systematically vary one parameter at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 2.3097 - accuracy: 0.1157 - val_loss: 2.3132 - val_accuracy: 0.1000\n",
      "Epoch 2/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 2.3084 - accuracy: 0.1133 - val_loss: 2.3147 - val_accuracy: 0.0930\n",
      "Epoch 3/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 2.3062 - accuracy: 0.1090 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
      "Epoch 4/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 2.3100 - accuracy: 0.0963 - val_loss: 2.3062 - val_accuracy: 0.0970\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-8764bf471e2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mvalacc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestacc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdo_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhiddensizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlearningrate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mplot_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mres\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlearningrate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalacc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtestacc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "# Learning rate\n",
    "res=[]\n",
    "for lr in [100, 10, 1, 0.1]:\n",
    "    valacc, testacc, history = do_all(hiddensizes, actfn, optimizer, lr*learningrate, n_train, n_valid, n_epochs, batch_size)\n",
    "    plot_history(history)\n",
    "    res += [[lr*learningrate,valacc,testacc]]\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "94/94 [==============================] - 2s 16ms/step - loss: 2.1164 - accuracy: 0.3863 - val_loss: 1.6802 - val_accuracy: 0.6530\n",
      "Epoch 2/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.9837 - accuracy: 0.7450 - val_loss: 0.6345 - val_accuracy: 0.8120\n",
      "Epoch 3/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5276 - accuracy: 0.8330 - val_loss: 0.5228 - val_accuracy: 0.8520\n",
      "Epoch 4/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.8680 - val_loss: 0.4760 - val_accuracy: 0.8480\n",
      "Epoch 5/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4004 - accuracy: 0.8720 - val_loss: 0.4432 - val_accuracy: 0.8680\n",
      "Epoch 6/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.3618 - accuracy: 0.8863 - val_loss: 0.4251 - val_accuracy: 0.8770\n",
      "Epoch 7/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.3359 - accuracy: 0.8930 - val_loss: 0.4320 - val_accuracy: 0.8820\n",
      "Epoch 8/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.3206 - accuracy: 0.9007 - val_loss: 0.4322 - val_accuracy: 0.8730\n",
      "Epoch 9/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.3052 - accuracy: 0.9067 - val_loss: 0.4383 - val_accuracy: 0.8730\n",
      "Epoch 10/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.2948 - accuracy: 0.9117 - val_loss: 0.4363 - val_accuracy: 0.8800\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-2aaf338d0e2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mvalacc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestacc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdo_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhiddensizes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearningrate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mplot_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mres\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalacc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtestacc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "# Number of layers\n",
    "res=[]\n",
    "for n in [1, 2, 3]:\n",
    "    valacc, testacc, history = do_all(hiddensizes[:n], actfn, optimizer, learningrate, n_train, n_valid, n_epochs, batch_size)\n",
    "    plot_history(history)\n",
    "    res += [[n,valacc,testacc]]\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "30/30 [==============================] - 0s 11ms/sample - loss: 2.2915 - accuracy: 0.1000 - val_loss: 2.3077 - val_accuracy: 0.1070\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 2.2901 - accuracy: 0.1000 - val_loss: 2.3073 - val_accuracy: 0.1080\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 2.2886 - accuracy: 0.1000 - val_loss: 2.3070 - val_accuracy: 0.1090\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 2.2871 - accuracy: 0.1000 - val_loss: 2.3067 - val_accuracy: 0.1110\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 2.2857 - accuracy: 0.1000 - val_loss: 2.3064 - val_accuracy: 0.1120\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 2.2842 - accuracy: 0.1000 - val_loss: 2.3060 - val_accuracy: 0.1120\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 2.2828 - accuracy: 0.1000 - val_loss: 2.3057 - val_accuracy: 0.1160\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 2.2814 - accuracy: 0.1000 - val_loss: 2.3054 - val_accuracy: 0.1170\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 2.2799 - accuracy: 0.1000 - val_loss: 2.3051 - val_accuracy: 0.1210\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 2.2785 - accuracy: 0.1000 - val_loss: 2.3048 - val_accuracy: 0.1230\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 2.2771 - accuracy: 0.1333 - val_loss: 2.3045 - val_accuracy: 0.1260\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 2.2758 - accuracy: 0.1333 - val_loss: 2.3042 - val_accuracy: 0.1290\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 2.2744 - accuracy: 0.1333 - val_loss: 2.3039 - val_accuracy: 0.1310\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 2.2730 - accuracy: 0.1333 - val_loss: 2.3036 - val_accuracy: 0.1320\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 2.2716 - accuracy: 0.1333 - val_loss: 2.3033 - val_accuracy: 0.1320\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 2.2701 - accuracy: 0.1333 - val_loss: 2.3030 - val_accuracy: 0.1380\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 2.2686 - accuracy: 0.1333 - val_loss: 2.3028 - val_accuracy: 0.1410\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 2.2671 - accuracy: 0.1333 - val_loss: 2.3025 - val_accuracy: 0.1430\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 2.2655 - accuracy: 0.1333 - val_loss: 2.3022 - val_accuracy: 0.1440\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 2.2640 - accuracy: 0.1333 - val_loss: 2.3019 - val_accuracy: 0.1450\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-e4e251ae11ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mntr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mn_train\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_train\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_train\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mvalacc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestacc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdo_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhiddensizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearningrate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mntr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mplot_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mres\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mntr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalacc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtestacc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "# Training set size\n",
    "res=[]\n",
    "for ntr in [n_train*0.01, n_train*0.1, n_train*0.5, n_train]:\n",
    "    valacc, testacc, history = do_all(hiddensizes, actfn, optimizer, learningrate, int(ntr), n_valid, n_epochs, batch_size)\n",
    "    plot_history(history)\n",
    "    res += [[int(ntr),valacc,testacc]]\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-17c4b74973ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Plot results (test accuracy vs factor that is changing)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'-o'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "# Plot results (test accuracy vs factor that is changing)\n",
    "res=np.array(res)\n",
    "plt.plot(res[:,0],res[:,2],'-o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
