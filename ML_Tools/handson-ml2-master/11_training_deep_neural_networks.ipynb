{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chapter 11 – Training Deep Neural Networks**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_This notebook contains all the sample code and solutions to the exercises in chapter 11._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/ageron/handson-ml2/blob/master/11_training_deep_neural_networks.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's import a few common modules, ensure MatplotLib plots figures inline and prepare a function to save the figures. We also check that Python 3.5 or later is installed (although Python 2.x may work, it is deprecated so we strongly recommend you use Python 3 instead), as well as Scikit-Learn ≥0.20 and TensorFlow ≥2.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"deep\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanishing/Exploding Gradients Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure sigmoid_saturation_plot\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "z = np.linspace(-5, 5, 200)\n",
    "\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([-5, 5], [1, 1], 'k--')\n",
    "plt.plot([0, 0], [-0.2, 1.2], 'k-')\n",
    "plt.plot([-5, 5], [-3/4, 7/4], 'g--')\n",
    "plt.plot(z, logit(z), \"b-\", linewidth=2)\n",
    "props = dict(facecolor='black', shrink=0.1)\n",
    "plt.annotate('Saturating', xytext=(3.5, 0.7), xy=(5, 1), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.annotate('Saturating', xytext=(-3.5, 0.3), xy=(-5, 0), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.annotate('Linear', xytext=(2, 0.2), xy=(0, 0.5), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.grid(True)\n",
    "plt.title(\"Sigmoid activation function\", fontsize=14)\n",
    "plt.axis([-5, 5, -0.2, 1.2])\n",
    "\n",
    "save_fig(\"sigmoid_saturation_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xavier and He Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Constant',\n",
       " 'GlorotNormal',\n",
       " 'GlorotUniform',\n",
       " 'Identity',\n",
       " 'Initializer',\n",
       " 'Ones',\n",
       " 'Orthogonal',\n",
       " 'RandomNormal',\n",
       " 'RandomUniform',\n",
       " 'TruncatedNormal',\n",
       " 'VarianceScaling',\n",
       " 'Zeros',\n",
       " 'constant',\n",
       " 'deserialize',\n",
       " 'get',\n",
       " 'glorot_normal',\n",
       " 'glorot_uniform',\n",
       " 'he_normal',\n",
       " 'he_uniform',\n",
       " 'identity',\n",
       " 'lecun_normal',\n",
       " 'lecun_uniform',\n",
       " 'ones',\n",
       " 'orthogonal',\n",
       " 'serialize',\n",
       " 'zeros']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[name for name in dir(keras.initializers) if not name.startswith(\"_\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x7f5488c3c450>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.layers.Dense(10, activation=\"relu\", kernel_initializer=\"he_normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x7f5407f90e50>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init = keras.initializers.VarianceScaling(scale=2., mode='fan_avg',\n",
    "                                          distribution='uniform')\n",
    "keras.layers.Dense(10, activation=\"relu\", kernel_initializer=init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nonsaturating Activation Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leaky ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leaky_relu(z, alpha=0.01):\n",
    "    return np.maximum(alpha*z, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure leaky_relu_plot\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(z, leaky_relu(z, 0.05), \"b-\", linewidth=2)\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([0, 0], [-0.5, 4.2], 'k-')\n",
    "plt.grid(True)\n",
    "props = dict(facecolor='black', shrink=0.1)\n",
    "plt.annotate('Leak', xytext=(-3.5, 0.5), xy=(-5, -0.2), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.title(\"Leaky ReLU activation function\", fontsize=14)\n",
    "plt.axis([-5, 5, -0.5, 4.2])\n",
    "\n",
    "save_fig(\"leaky_relu_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['deserialize',\n",
       " 'elu',\n",
       " 'exponential',\n",
       " 'get',\n",
       " 'hard_sigmoid',\n",
       " 'linear',\n",
       " 'relu',\n",
       " 'selu',\n",
       " 'serialize',\n",
       " 'sigmoid',\n",
       " 'softmax',\n",
       " 'softplus',\n",
       " 'softsign',\n",
       " 'swish',\n",
       " 'tanh']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[m for m in dir(keras.activations) if not m.startswith(\"_\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LeakyReLU', 'PReLU', 'ReLU', 'ThresholdedReLU']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[m for m in dir(keras.layers) if \"relu\" in m.lower()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train a neural network on Fashion MNIST using the Leaky ReLU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "X_train_full = X_train_full / 255.0\n",
    "X_test = X_test / 255.0\n",
    "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.LeakyReLU(),\n",
    "    keras.layers.Dense(100, kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.LeakyReLU(),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 1.2819 - accuracy: 0.6229 - val_loss: 0.8886 - val_accuracy: 0.7160\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.7955 - accuracy: 0.7362 - val_loss: 0.7130 - val_accuracy: 0.7656\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.6816 - accuracy: 0.7721 - val_loss: 0.6427 - val_accuracy: 0.7898\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.6217 - accuracy: 0.7944 - val_loss: 0.5900 - val_accuracy: 0.8066\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.5832 - accuracy: 0.8075 - val_loss: 0.5582 - val_accuracy: 0.8202\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.5553 - accuracy: 0.8157 - val_loss: 0.5350 - val_accuracy: 0.8238\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.5338 - accuracy: 0.8224 - val_loss: 0.5157 - val_accuracy: 0.8304\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.5172 - accuracy: 0.8273 - val_loss: 0.5079 - val_accuracy: 0.8286\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.5040 - accuracy: 0.8289 - val_loss: 0.4895 - val_accuracy: 0.8390\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4924 - accuracy: 0.8321 - val_loss: 0.4817 - val_accuracy: 0.8394\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try PReLU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.PReLU(),\n",
    "    keras.layers.Dense(100, kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.PReLU(),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 1.3461 - accuracy: 0.6209 - val_loss: 0.9255 - val_accuracy: 0.7186\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.8197 - accuracy: 0.7355 - val_loss: 0.7305 - val_accuracy: 0.7630\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.6966 - accuracy: 0.7694 - val_loss: 0.6565 - val_accuracy: 0.7880\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.6331 - accuracy: 0.7909 - val_loss: 0.6003 - val_accuracy: 0.8048\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.5917 - accuracy: 0.8057 - val_loss: 0.5656 - val_accuracy: 0.8178\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.5618 - accuracy: 0.8135 - val_loss: 0.5406 - val_accuracy: 0.8238\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.5390 - accuracy: 0.8205 - val_loss: 0.5196 - val_accuracy: 0.8314\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.5213 - accuracy: 0.8257 - val_loss: 0.5113 - val_accuracy: 0.8314\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.5070 - accuracy: 0.8289 - val_loss: 0.4916 - val_accuracy: 0.8378\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4945 - accuracy: 0.8315 - val_loss: 0.4826 - val_accuracy: 0.8396\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ELU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elu(z, alpha=1):\n",
    "    return np.where(z < 0, alpha * (np.exp(z) - 1), z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure elu_plot\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(z, elu(z), \"b-\", linewidth=2)\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([-5, 5], [-1, -1], 'k--')\n",
    "plt.plot([0, 0], [-2.2, 3.2], 'k-')\n",
    "plt.grid(True)\n",
    "plt.title(r\"ELU activation function ($\\alpha=1$)\", fontsize=14)\n",
    "plt.axis([-5, 5, -2.2, 3.2])\n",
    "\n",
    "save_fig(\"elu_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing ELU in TensorFlow is trivial, just specify the activation function when building each layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x7f5407faac50>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.layers.Dense(10, activation=\"elu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SELU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This activation function was proposed in this [great paper](https://arxiv.org/pdf/1706.02515.pdf) by Günter Klambauer, Thomas Unterthiner and Andreas Mayr, published in June 2017. During training, a neural network composed exclusively of a stack of dense layers using the SELU activation function and LeCun initialization will self-normalize: the output of each layer will tend to preserve the same mean and variance during training, which solves the vanishing/exploding gradients problem. As a result, this activation function outperforms the other activation functions very significantly for such neural nets, so you should really try it out. Unfortunately, the self-normalizing property of the SELU activation function is easily broken: you cannot use ℓ<sub>1</sub> or ℓ<sub>2</sub> regularization, regular dropout, max-norm, skip connections or other non-sequential topologies (so recurrent neural networks won't self-normalize). However, in practice it works quite well with sequential CNNs. If you break self-normalization, SELU will not necessarily outperform other activation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import erfc\n",
    "\n",
    "# alpha and scale to self normalize with mean 0 and standard deviation 1\n",
    "# (see equation 14 in the paper):\n",
    "alpha_0_1 = -np.sqrt(2 / np.pi) / (erfc(1/np.sqrt(2)) * np.exp(1/2) - 1)\n",
    "scale_0_1 = (1 - erfc(1 / np.sqrt(2)) * np.sqrt(np.e)) * np.sqrt(2 * np.pi) * (2 * erfc(np.sqrt(2))*np.e**2 + np.pi*erfc(1/np.sqrt(2))**2*np.e - 2*(2+np.pi)*erfc(1/np.sqrt(2))*np.sqrt(np.e)+np.pi+2)**(-1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selu(z, scale=scale_0_1, alpha=alpha_0_1):\n",
    "    return scale * elu(z, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure selu_plot\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(z, selu(z), \"b-\", linewidth=2)\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([-5, 5], [-1.758, -1.758], 'k--')\n",
    "plt.plot([0, 0], [-2.2, 3.2], 'k-')\n",
    "plt.grid(True)\n",
    "plt.title(\"SELU activation function\", fontsize=14)\n",
    "plt.axis([-5, 5, -2.2, 3.2])\n",
    "\n",
    "save_fig(\"selu_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the SELU hyperparameters (`scale` and `alpha`) are tuned in such a way that the mean output of each neuron remains close to 0, and the standard deviation remains close to 1 (assuming the inputs are standardized with mean 0 and standard deviation 1 too). Using this activation function, even a 1,000 layer deep neural network preserves roughly mean 0 and standard deviation 1 across all layers, avoiding the exploding/vanishing gradients problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0: mean -0.00, std deviation 1.00\n",
      "Layer 100: mean 0.02, std deviation 0.96\n",
      "Layer 200: mean 0.01, std deviation 0.90\n",
      "Layer 300: mean -0.02, std deviation 0.92\n",
      "Layer 400: mean 0.05, std deviation 0.89\n",
      "Layer 500: mean 0.01, std deviation 0.93\n",
      "Layer 600: mean 0.02, std deviation 0.92\n",
      "Layer 700: mean -0.02, std deviation 0.90\n",
      "Layer 800: mean 0.05, std deviation 0.83\n",
      "Layer 900: mean 0.02, std deviation 1.00\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "Z = np.random.normal(size=(500, 100)) # standardized inputs\n",
    "for layer in range(1000):\n",
    "    W = np.random.normal(size=(100, 100), scale=np.sqrt(1 / 100)) # LeCun initialization\n",
    "    Z = selu(np.dot(Z, W))\n",
    "    means = np.mean(Z, axis=0).mean()\n",
    "    stds = np.std(Z, axis=0).mean()\n",
    "    if layer % 100 == 0:\n",
    "        print(\"Layer {}: mean {:.2f}, std deviation {:.2f}\".format(layer, means, stds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using SELU is easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x7f5407faa8d0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.layers.Dense(10, activation=\"selu\",\n",
    "                   kernel_initializer=\"lecun_normal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a neural net for Fashion MNIST with 100 hidden layers, using the SELU activation function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "model.add(keras.layers.Dense(300, activation=\"selu\",\n",
    "                             kernel_initializer=\"lecun_normal\"))\n",
    "for layer in range(99):\n",
    "    model.add(keras.layers.Dense(100, activation=\"selu\",\n",
    "                                 kernel_initializer=\"lecun_normal\"))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train it. Do not forget to scale the inputs to mean 0 and standard deviation 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_means = X_train.mean(axis=0, keepdims=True)\n",
    "pixel_stds = X_train.std(axis=0, keepdims=True)\n",
    "X_train_scaled = (X_train - pixel_means) / pixel_stds\n",
    "X_valid_scaled = (X_valid - pixel_means) / pixel_stds\n",
    "X_test_scaled = (X_test - pixel_means) / pixel_stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 1.7729 - accuracy: 0.3071 - val_loss: 1.3899 - val_accuracy: 0.4524\n",
      "Epoch 2/5\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 1.0602 - accuracy: 0.5860 - val_loss: 0.7820 - val_accuracy: 0.7254\n",
      "Epoch 3/5\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 0.8437 - accuracy: 0.6949 - val_loss: 0.7487 - val_accuracy: 0.7022\n",
      "Epoch 4/5\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.7273 - accuracy: 0.7344 - val_loss: 0.8475 - val_accuracy: 0.6896\n",
      "Epoch 5/5\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.7665 - accuracy: 0.7226 - val_loss: 0.6661 - val_accuracy: 0.7730\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled, y_train, epochs=5,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now look at what happens if we try to use the ReLU activation function instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "model.add(keras.layers.Dense(300, activation=\"relu\", kernel_initializer=\"he_normal\"))\n",
    "for layer in range(99):\n",
    "    model.add(keras.layers.Dense(100, activation=\"relu\", kernel_initializer=\"he_normal\"))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 1.9751 - accuracy: 0.2315 - val_loss: 1.9868 - val_accuracy: 0.2896\n",
      "Epoch 2/5\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 1.3886 - accuracy: 0.4257 - val_loss: 1.0659 - val_accuracy: 0.5542\n",
      "Epoch 3/5\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 1.2192 - accuracy: 0.4824 - val_loss: 1.0226 - val_accuracy: 0.5972\n",
      "Epoch 4/5\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 0.9435 - accuracy: 0.6122 - val_loss: 0.9141 - val_accuracy: 0.6054\n",
      "Epoch 5/5\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 0.8532 - accuracy: 0.6520 - val_loss: 0.7514 - val_accuracy: 0.7030\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled, y_train, epochs=5,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not great at all, we suffered from the vanishing/exploding gradients problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_4 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 784)               3136      \n",
      "_________________________________________________________________\n",
      "dense_212 (Dense)            (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 300)               1200      \n",
      "_________________________________________________________________\n",
      "dense_213 (Dense)            (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_214 (Dense)            (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 271,346\n",
      "Trainable params: 268,978\n",
      "Non-trainable params: 2,368\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('batch_normalization/gamma:0', True),\n",
       " ('batch_normalization/beta:0', True),\n",
       " ('batch_normalization/moving_mean:0', False),\n",
       " ('batch_normalization/moving_variance:0', False)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn1 = model.layers[1]\n",
    "[(var.name, var.trainable) for var in bn1.variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'cond/Identity' type=Identity>,\n",
       " <tf.Operation 'cond_1/Identity' type=Identity>]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn1.updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.8661 - accuracy: 0.7120 - val_loss: 0.5674 - val_accuracy: 0.8064\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.5733 - accuracy: 0.8015 - val_loss: 0.4864 - val_accuracy: 0.8378\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.5143 - accuracy: 0.8223 - val_loss: 0.4479 - val_accuracy: 0.8454\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4763 - accuracy: 0.8349 - val_loss: 0.4259 - val_accuracy: 0.8562\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4517 - accuracy: 0.8429 - val_loss: 0.4105 - val_accuracy: 0.8618\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4356 - accuracy: 0.8470 - val_loss: 0.3985 - val_accuracy: 0.8654\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4217 - accuracy: 0.8515 - val_loss: 0.3886 - val_accuracy: 0.8656\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4111 - accuracy: 0.8564 - val_loss: 0.3813 - val_accuracy: 0.8702\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3999 - accuracy: 0.8595 - val_loss: 0.3750 - val_accuracy: 0.8716\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3899 - accuracy: 0.8611 - val_loss: 0.3683 - val_accuracy: 0.8738\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes applying BN before the activation function works better (there's a debate on this topic). Moreover, the layer before a `BatchNormalization` layer does not need to have bias terms, since the `BatchNormalization` layer some as well, it would be a waste of parameters, so you can set `use_bias=False` when creating those layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(300, use_bias=False),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Activation(\"relu\"),\n",
    "    keras.layers.Dense(100, use_bias=False),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Activation(\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 1.0569 - accuracy: 0.6798 - val_loss: 0.6812 - val_accuracy: 0.7876\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.6827 - accuracy: 0.7813 - val_loss: 0.5585 - val_accuracy: 0.8230\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.5990 - accuracy: 0.8014 - val_loss: 0.5021 - val_accuracy: 0.8362\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.5466 - accuracy: 0.8161 - val_loss: 0.4671 - val_accuracy: 0.8444\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.5139 - accuracy: 0.8249 - val_loss: 0.4439 - val_accuracy: 0.8526\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4915 - accuracy: 0.8309 - val_loss: 0.4263 - val_accuracy: 0.8592\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4738 - accuracy: 0.8374 - val_loss: 0.4135 - val_accuracy: 0.8598\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4589 - accuracy: 0.8413 - val_loss: 0.4033 - val_accuracy: 0.8642\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4473 - accuracy: 0.8445 - val_loss: 0.3945 - val_accuracy: 0.8668\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4339 - accuracy: 0.8479 - val_loss: 0.3866 - val_accuracy: 0.8676\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Clipping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All Keras optimizers accept `clipnorm` or `clipvalue` arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(clipvalue=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(clipnorm=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reusing Pretrained Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reusing a Keras model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split the fashion MNIST training set in two:\n",
    "* `X_train_A`: all images of all items except for sandals and shirts (classes 5 and 6).\n",
    "* `X_train_B`: a much smaller training set of just the first 200 images of sandals or shirts.\n",
    "\n",
    "The validation set and the test set are also split this way, but without restricting the number of images.\n",
    "\n",
    "We will train a model on set A (classification task with 8 classes), and try to reuse it to tackle set B (binary classification). We hope to transfer a little bit of knowledge from task A to task B, since classes in set A (sneakers, ankle boots, coats, t-shirts, etc.) are somewhat similar to classes in set B (sandals and shirts). However, since we are using `Dense` layers, only patterns that occur at the same location can be reused (in contrast, convolutional layers will transfer much better, since learned patterns can be detected anywhere on the image, as we will see in the CNN chapter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(X, y):\n",
    "    y_5_or_6 = (y == 5) | (y == 6) # sandals or shirts\n",
    "    y_A = y[~y_5_or_6]\n",
    "    y_A[y_A > 6] -= 2 # class indices 7, 8, 9 should be moved to 5, 6, 7\n",
    "    y_B = (y[y_5_or_6] == 6).astype(np.float32) # binary classification task: is it a shirt (class 6)?\n",
    "    return ((X[~y_5_or_6], y_A),\n",
    "            (X[y_5_or_6], y_B))\n",
    "\n",
    "(X_train_A, y_train_A), (X_train_B, y_train_B) = split_dataset(X_train, y_train)\n",
    "(X_valid_A, y_valid_A), (X_valid_B, y_valid_B) = split_dataset(X_valid, y_valid)\n",
    "(X_test_A, y_test_A), (X_test_B, y_test_B) = split_dataset(X_test, y_test)\n",
    "X_train_B = X_train_B[:200]\n",
    "y_train_B = y_train_B[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43986, 28, 28)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 28, 28)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 0, 5, 7, 7, 7, 4, 4, 3, 4, 0, 1, 6, 3, 4, 3, 2, 6, 5, 3, 4, 5,\n",
       "       1, 3, 4, 2, 0, 6, 7, 1], dtype=uint8)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_A[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1.], dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_B[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A = keras.models.Sequential()\n",
    "model_A.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "for n_hidden in (300, 100, 50, 50, 50):\n",
    "    model_A.add(keras.layers.Dense(n_hidden, activation=\"selu\"))\n",
    "model_A.add(keras.layers.Dense(8, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1375/1375 [==============================] - 2s 1ms/step - loss: 0.5926 - accuracy: 0.8103 - val_loss: 0.3894 - val_accuracy: 0.8667\n",
      "Epoch 2/20\n",
      "1375/1375 [==============================] - 2s 1ms/step - loss: 0.3523 - accuracy: 0.8787 - val_loss: 0.3289 - val_accuracy: 0.8827\n",
      "Epoch 3/20\n",
      "1375/1375 [==============================] - 2s 1ms/step - loss: 0.3170 - accuracy: 0.8894 - val_loss: 0.3012 - val_accuracy: 0.8996\n",
      "Epoch 4/20\n",
      "1375/1375 [==============================] - 2s 1ms/step - loss: 0.2973 - accuracy: 0.8975 - val_loss: 0.2893 - val_accuracy: 0.9026\n",
      "Epoch 5/20\n",
      "1375/1375 [==============================] - 2s 1ms/step - loss: 0.2835 - accuracy: 0.9021 - val_loss: 0.2773 - val_accuracy: 0.9061\n",
      "Epoch 6/20\n",
      "1375/1375 [==============================] - 2s 1ms/step - loss: 0.2730 - accuracy: 0.9061 - val_loss: 0.2734 - val_accuracy: 0.9073\n",
      "Epoch 7/20\n",
      "1375/1375 [==============================] - 2s 1ms/step - loss: 0.2641 - accuracy: 0.9092 - val_loss: 0.2723 - val_accuracy: 0.9083\n",
      "Epoch 8/20\n",
      "1375/1375 [==============================] - 2s 1ms/step - loss: 0.2573 - accuracy: 0.9128 - val_loss: 0.2589 - val_accuracy: 0.9136\n",
      "Epoch 9/20\n",
      "1375/1375 [==============================] - 2s 1ms/step - loss: 0.2518 - accuracy: 0.9135 - val_loss: 0.2564 - val_accuracy: 0.9145\n",
      "Epoch 10/20\n",
      "1375/1375 [==============================] - 2s 1ms/step - loss: 0.2469 - accuracy: 0.9154 - val_loss: 0.2543 - val_accuracy: 0.9153\n",
      "Epoch 11/20\n",
      "1375/1375 [==============================] - 2s 1ms/step - loss: 0.2422 - accuracy: 0.9177 - val_loss: 0.2497 - val_accuracy: 0.9148\n",
      "Epoch 12/20\n",
      "1375/1375 [==============================] - 2s 1ms/step - loss: 0.2382 - accuracy: 0.9187 - val_loss: 0.2517 - val_accuracy: 0.9123\n",
      "Epoch 13/20\n",
      "1375/1375 [==============================] - 2s 1ms/step - loss: 0.2349 - accuracy: 0.9198 - val_loss: 0.2445 - val_accuracy: 0.9163\n",
      "Epoch 14/20\n",
      "1375/1375 [==============================] - 2s 1ms/step - loss: 0.2314 - accuracy: 0.9215 - val_loss: 0.2415 - val_accuracy: 0.9178\n",
      "Epoch 15/20\n",
      "1375/1375 [==============================] - 2s 1ms/step - loss: 0.2286 - accuracy: 0.9214 - val_loss: 0.2445 - val_accuracy: 0.9190\n",
      "Epoch 16/20\n",
      "1375/1375 [==============================] - 2s 1ms/step - loss: 0.2253 - accuracy: 0.9224 - val_loss: 0.2384 - val_accuracy: 0.9198\n",
      "Epoch 17/20\n",
      "1375/1375 [==============================] - 2s 1ms/step - loss: 0.2229 - accuracy: 0.9234 - val_loss: 0.2408 - val_accuracy: 0.9175\n",
      "Epoch 18/20\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2200 - accuracy: 0.9246 - val_loss: 0.2428 - val_accuracy: 0.9153\n",
      "Epoch 19/20\n",
      "1375/1375 [==============================] - 2s 1ms/step - loss: 0.2176 - accuracy: 0.9252 - val_loss: 0.2329 - val_accuracy: 0.9205\n",
      "Epoch 20/20\n",
      "1375/1375 [==============================] - 2s 1ms/step - loss: 0.2155 - accuracy: 0.9262 - val_loss: 0.2330 - val_accuracy: 0.9205\n"
     ]
    }
   ],
   "source": [
    "history = model_A.fit(X_train_A, y_train_A, epochs=20,\n",
    "                    validation_data=(X_valid_A, y_valid_A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A.save(\"my_model_A.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B = keras.models.Sequential()\n",
    "model_B.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "for n_hidden in (300, 100, 50, 50, 50):\n",
    "    model_B.add(keras.layers.Dense(n_hidden, activation=\"selu\"))\n",
    "model_B.add(keras.layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.9573 - accuracy: 0.4650 - val_loss: 0.6314 - val_accuracy: 0.6004\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5692 - accuracy: 0.7450 - val_loss: 0.4784 - val_accuracy: 0.8529\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4503 - accuracy: 0.8650 - val_loss: 0.4102 - val_accuracy: 0.8945\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3879 - accuracy: 0.8950 - val_loss: 0.3647 - val_accuracy: 0.9178\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3435 - accuracy: 0.9250 - val_loss: 0.3300 - val_accuracy: 0.9320\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3081 - accuracy: 0.9300 - val_loss: 0.3019 - val_accuracy: 0.9402\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2800 - accuracy: 0.9350 - val_loss: 0.2804 - val_accuracy: 0.9422\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2564 - accuracy: 0.9450 - val_loss: 0.2606 - val_accuracy: 0.9473\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.2362 - accuracy: 0.9550 - val_loss: 0.2428 - val_accuracy: 0.9523\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.2188 - accuracy: 0.9600 - val_loss: 0.2281 - val_accuracy: 0.9544\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2036 - accuracy: 0.9700 - val_loss: 0.2150 - val_accuracy: 0.9584\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1898 - accuracy: 0.9700 - val_loss: 0.2036 - val_accuracy: 0.9584\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1773 - accuracy: 0.9750 - val_loss: 0.1931 - val_accuracy: 0.9615\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.1668 - accuracy: 0.9800 - val_loss: 0.1838 - val_accuracy: 0.9635\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.1570 - accuracy: 0.9900 - val_loss: 0.1746 - val_accuracy: 0.9686\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.1481 - accuracy: 0.9900 - val_loss: 0.1674 - val_accuracy: 0.9686\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1406 - accuracy: 0.9900 - val_loss: 0.1604 - val_accuracy: 0.9706\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.1334 - accuracy: 0.9900 - val_loss: 0.1539 - val_accuracy: 0.9706\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.1268 - accuracy: 0.9900 - val_loss: 0.1482 - val_accuracy: 0.9716\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.1208 - accuracy: 0.9900 - val_loss: 0.1431 - val_accuracy: 0.9716\n"
     ]
    }
   ],
   "source": [
    "history = model_B.fit(X_train_B, y_train_B, epochs=20,\n",
    "                      validation_data=(X_valid_B, y_valid_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_5 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 784)               3136      \n",
      "_________________________________________________________________\n",
      "dense_215 (Dense)            (None, 300)               235200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 300)               1200      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_216 (Dense)            (None, 100)               30000     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_217 (Dense)            (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 270,946\n",
      "Trainable params: 268,578\n",
      "Non-trainable params: 2,368\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A = keras.models.load_model(\"my_model_A.h5\")\n",
    "model_B_on_A = keras.models.Sequential(model_A.layers[:-1])\n",
    "model_B_on_A.add(keras.layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A_clone = keras.models.clone_model(model_A)\n",
    "model_A_clone.set_weights(model_A.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model_B_on_A.compile(loss=\"binary_crossentropy\",\n",
    "                     optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "                     metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.4442 - accuracy: 0.8350 - val_loss: 0.4399 - val_accuracy: 0.8205\n",
      "Epoch 2/4\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4124 - accuracy: 0.8550 - val_loss: 0.4112 - val_accuracy: 0.8327\n",
      "Epoch 3/4\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3842 - accuracy: 0.8650 - val_loss: 0.3850 - val_accuracy: 0.8479\n",
      "Epoch 4/4\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3585 - accuracy: 0.8700 - val_loss: 0.3624 - val_accuracy: 0.8540\n",
      "Epoch 1/16\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.2927 - accuracy: 0.9250 - val_loss: 0.2480 - val_accuracy: 0.9533\n",
      "Epoch 2/16\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2057 - accuracy: 0.9850 - val_loss: 0.1965 - val_accuracy: 0.9787\n",
      "Epoch 3/16\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.1632 - accuracy: 0.9900 - val_loss: 0.1654 - val_accuracy: 0.9899\n",
      "Epoch 4/16\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.1360 - accuracy: 1.0000 - val_loss: 0.1453 - val_accuracy: 0.9929\n",
      "Epoch 5/16\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.1183 - accuracy: 1.0000 - val_loss: 0.1303 - val_accuracy: 0.9929\n",
      "Epoch 6/16\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.1047 - accuracy: 1.0000 - val_loss: 0.1189 - val_accuracy: 0.9929\n",
      "Epoch 7/16\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0944 - accuracy: 1.0000 - val_loss: 0.1098 - val_accuracy: 0.9929\n",
      "Epoch 8/16\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0860 - accuracy: 1.0000 - val_loss: 0.1020 - val_accuracy: 0.9919\n",
      "Epoch 9/16\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0788 - accuracy: 1.0000 - val_loss: 0.0956 - val_accuracy: 0.9919\n",
      "Epoch 10/16\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0729 - accuracy: 1.0000 - val_loss: 0.0901 - val_accuracy: 0.9919\n",
      "Epoch 11/16\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0678 - accuracy: 1.0000 - val_loss: 0.0853 - val_accuracy: 0.9919\n",
      "Epoch 12/16\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0633 - accuracy: 1.0000 - val_loss: 0.0810 - val_accuracy: 0.9919\n",
      "Epoch 13/16\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0593 - accuracy: 1.0000 - val_loss: 0.0772 - val_accuracy: 0.9919\n",
      "Epoch 14/16\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0557 - accuracy: 1.0000 - val_loss: 0.0740 - val_accuracy: 0.9929\n",
      "Epoch 15/16\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0527 - accuracy: 1.0000 - val_loss: 0.0711 - val_accuracy: 0.9929\n",
      "Epoch 16/16\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0501 - accuracy: 1.0000 - val_loss: 0.0685 - val_accuracy: 0.9929\n"
     ]
    }
   ],
   "source": [
    "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=4,\n",
    "                           validation_data=(X_valid_B, y_valid_B))\n",
    "\n",
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = True\n",
    "\n",
    "model_B_on_A.compile(loss=\"binary_crossentropy\",\n",
    "                     optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "                     metrics=[\"accuracy\"])\n",
    "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=16,\n",
    "                           validation_data=(X_valid_B, y_valid_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, what's the final verdict?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 1ms/step - loss: 0.1408 - accuracy: 0.9705\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1408407837152481, 0.9704999923706055]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_B.evaluate(X_test_B, y_test_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0635 - accuracy: 0.9980\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06351099163293839, 0.9980000257492065]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_B_on_A.evaluate(X_test_B, y_test_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We got quite a bit of transfer: the error rate dropped by a factor of 4!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.066666666666663"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(100 - 96.95) / (100 - 99.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Faster Optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Momentum optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nesterov Accelerated Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(lr=0.001, momentum=0.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaGrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adagrad(lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMSProp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.RMSprop(lr=0.001, rho=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adam Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adamax Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adamax(lr=0.001, beta_1=0.9, beta_2=0.999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nadam Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Nadam(lr=0.001, beta_1=0.9, beta_2=0.999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Rate Scheduling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Power Scheduling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```lr = lr0 / (1 + steps / s)**c```\n",
    "* Keras uses `c=1` and `s = 1 / decay`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(lr=0.01, decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4842 - accuracy: 0.8287 - val_loss: 0.4028 - val_accuracy: 0.8628\n",
      "Epoch 2/25\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3760 - accuracy: 0.8661 - val_loss: 0.3760 - val_accuracy: 0.8668\n",
      "Epoch 3/25\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3435 - accuracy: 0.8775 - val_loss: 0.3780 - val_accuracy: 0.8716\n",
      "Epoch 4/25\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3224 - accuracy: 0.8840 - val_loss: 0.3542 - val_accuracy: 0.8772\n",
      "Epoch 5/25\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3073 - accuracy: 0.8904 - val_loss: 0.3489 - val_accuracy: 0.8744\n",
      "Epoch 6/25\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2934 - accuracy: 0.8955 - val_loss: 0.3462 - val_accuracy: 0.8792\n",
      "Epoch 7/25\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2837 - accuracy: 0.8986 - val_loss: 0.3414 - val_accuracy: 0.8818\n",
      "Epoch 8/25\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2745 - accuracy: 0.9025 - val_loss: 0.3450 - val_accuracy: 0.8794\n",
      "Epoch 9/25\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2665 - accuracy: 0.9044 - val_loss: 0.3352 - val_accuracy: 0.8846\n",
      "Epoch 10/25\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2591 - accuracy: 0.9072 - val_loss: 0.3300 - val_accuracy: 0.8850\n",
      "Epoch 11/25\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2532 - accuracy: 0.9094 - val_loss: 0.3309 - val_accuracy: 0.8836\n",
      "Epoch 12/25\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2473 - accuracy: 0.9123 - val_loss: 0.3370 - val_accuracy: 0.8804\n",
      "Epoch 13/25\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2420 - accuracy: 0.9147 - val_loss: 0.3293 - val_accuracy: 0.8870\n",
      "Epoch 14/25\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2380 - accuracy: 0.9163 - val_loss: 0.3311 - val_accuracy: 0.8850\n",
      "Epoch 15/25\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2332 - accuracy: 0.9170 - val_loss: 0.3271 - val_accuracy: 0.8856\n",
      "Epoch 16/25\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2292 - accuracy: 0.9192 - val_loss: 0.3262 - val_accuracy: 0.8870\n",
      "Epoch 17/25\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2254 - accuracy: 0.9204 - val_loss: 0.3280 - val_accuracy: 0.8878\n",
      "Epoch 18/25\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2215 - accuracy: 0.9224 - val_loss: 0.3247 - val_accuracy: 0.8874\n",
      "Epoch 19/25\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2184 - accuracy: 0.9233 - val_loss: 0.3268 - val_accuracy: 0.8876\n",
      "Epoch 20/25\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2153 - accuracy: 0.9245 - val_loss: 0.3246 - val_accuracy: 0.8894\n",
      "Epoch 21/25\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2118 - accuracy: 0.9262 - val_loss: 0.3255 - val_accuracy: 0.8890\n",
      "Epoch 22/25\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2093 - accuracy: 0.9277 - val_loss: 0.3228 - val_accuracy: 0.8902\n",
      "Epoch 23/25\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2065 - accuracy: 0.9278 - val_loss: 0.3240 - val_accuracy: 0.8894\n",
      "Epoch 24/25\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2036 - accuracy: 0.9302 - val_loss: 0.3256 - val_accuracy: 0.8908\n",
      "Epoch 25/25\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2017 - accuracy: 0.9300 - val_loss: 0.3250 - val_accuracy: 0.8920\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 25\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "decay = 1e-4\n",
    "batch_size = 32\n",
    "n_steps_per_epoch = len(X_train) // batch_size\n",
    "epochs = np.arange(n_epochs)\n",
    "lrs = learning_rate / (1 + decay * epochs * n_steps_per_epoch)\n",
    "\n",
    "plt.plot(epochs, lrs,  \"o-\")\n",
    "plt.axis([0, n_epochs - 1, 0, 0.01])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.title(\"Power Scheduling\", fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponential Scheduling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```lr = lr0 * 0.1**(epoch / s)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_decay_fn(epoch):\n",
    "    return 0.01 * 0.1**(epoch / 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_decay(lr0, s):\n",
    "    def exponential_decay_fn(epoch):\n",
    "        return lr0 * 0.1**(epoch / s)\n",
    "    return exponential_decay_fn\n",
    "\n",
    "exponential_decay_fn = exponential_decay(lr0=0.01, s=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "n_epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.8262 - accuracy: 0.7655 - val_loss: 0.9051 - val_accuracy: 0.7452 - lr: 0.0100\n",
      "Epoch 2/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.7111 - accuracy: 0.7871 - val_loss: 0.5687 - val_accuracy: 0.8198 - lr: 0.0089\n",
      "Epoch 3/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.5997 - accuracy: 0.8137 - val_loss: 0.8987 - val_accuracy: 0.7484 - lr: 0.0079\n",
      "Epoch 4/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.5658 - accuracy: 0.8283 - val_loss: 0.5530 - val_accuracy: 0.8304 - lr: 0.0071\n",
      "Epoch 5/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4921 - accuracy: 0.8439 - val_loss: 0.4996 - val_accuracy: 0.8562 - lr: 0.0063\n",
      "Epoch 6/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4494 - accuracy: 0.8580 - val_loss: 0.5258 - val_accuracy: 0.8466 - lr: 0.0056\n",
      "Epoch 7/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4313 - accuracy: 0.8651 - val_loss: 0.5572 - val_accuracy: 0.8562 - lr: 0.0050\n",
      "Epoch 8/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3822 - accuracy: 0.8752 - val_loss: 0.5476 - val_accuracy: 0.8492 - lr: 0.0045\n",
      "Epoch 9/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3561 - accuracy: 0.8841 - val_loss: 0.4874 - val_accuracy: 0.8558 - lr: 0.0040\n",
      "Epoch 10/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3289 - accuracy: 0.8905 - val_loss: 0.4533 - val_accuracy: 0.8786 - lr: 0.0035\n",
      "Epoch 11/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3058 - accuracy: 0.8957 - val_loss: 0.4763 - val_accuracy: 0.8762 - lr: 0.0032\n",
      "Epoch 12/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2880 - accuracy: 0.9027 - val_loss: 0.5242 - val_accuracy: 0.8746 - lr: 0.0028\n",
      "Epoch 13/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2691 - accuracy: 0.9083 - val_loss: 0.4683 - val_accuracy: 0.8848 - lr: 0.0025\n",
      "Epoch 14/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2493 - accuracy: 0.9139 - val_loss: 0.4739 - val_accuracy: 0.8724 - lr: 0.0022\n",
      "Epoch 15/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2309 - accuracy: 0.9196 - val_loss: 0.4799 - val_accuracy: 0.8832 - lr: 0.0020\n",
      "Epoch 16/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2123 - accuracy: 0.9261 - val_loss: 0.4820 - val_accuracy: 0.8866 - lr: 0.0018\n",
      "Epoch 17/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1994 - accuracy: 0.9294 - val_loss: 0.4854 - val_accuracy: 0.8862 - lr: 0.0016\n",
      "Epoch 18/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1865 - accuracy: 0.9349 - val_loss: 0.5005 - val_accuracy: 0.8850 - lr: 0.0014\n",
      "Epoch 19/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1712 - accuracy: 0.9417 - val_loss: 0.5025 - val_accuracy: 0.8934 - lr: 0.0013\n",
      "Epoch 20/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1608 - accuracy: 0.9443 - val_loss: 0.5122 - val_accuracy: 0.8922 - lr: 0.0011\n",
      "Epoch 21/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1502 - accuracy: 0.9490 - val_loss: 0.5309 - val_accuracy: 0.8884 - lr: 0.0010\n",
      "Epoch 22/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1403 - accuracy: 0.9520 - val_loss: 0.5553 - val_accuracy: 0.8900 - lr: 8.9125e-04\n",
      "Epoch 23/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1323 - accuracy: 0.9562 - val_loss: 0.5686 - val_accuracy: 0.8880 - lr: 7.9433e-04\n",
      "Epoch 24/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1242 - accuracy: 0.9583 - val_loss: 0.5944 - val_accuracy: 0.8916 - lr: 7.0795e-04\n",
      "Epoch 25/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1151 - accuracy: 0.9610 - val_loss: 0.6329 - val_accuracy: 0.8868 - lr: 6.3096e-04\n"
     ]
    }
   ],
   "source": [
    "lr_scheduler = keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid),\n",
    "                    callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.epoch, history.history[\"lr\"], \"o-\")\n",
    "plt.axis([0, n_epochs - 1, 0, 0.011])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.title(\"Exponential Scheduling\", fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    " K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The schedule function can take the current learning rate as a second argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_decay_fn(epoch, lr):\n",
    "    return lr * 0.1**(1 / 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to update the learning rate at each iteration rather than at each epoch, you must write your own callback class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = keras.backend\n",
    "\n",
    "class ExponentialDecay(keras.callbacks.Callback):\n",
    "    def __init__(self, s=40000):\n",
    "        super().__init__()\n",
    "        self.s = s\n",
    "\n",
    "    def on_batch_begin(self, batch, logs=None):\n",
    "        # Note: the `batch` argument is reset at each epoch\n",
    "        lr = K.get_value(self.model.optimizer.lr)\n",
    "        K.set_value(self.model.optimizer.lr, lr * 0.1**(1 / s))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        logs['lr'] = K.get_value(self.model.optimizer.lr)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "lr0 = 0.01\n",
    "optimizer = keras.optimizers.Nadam(lr=lr0)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "n_epochs = 25\n",
    "\n",
    "s = 20 * len(X_train) // 32 # number of steps in 20 epochs (batch size = 32)\n",
    "exp_decay = ExponentialDecay(s)\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid),\n",
    "                    callbacks=[exp_decay])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = n_epochs * len(X_train) // 32\n",
    "steps = np.arange(n_steps)\n",
    "lrs = lr0 * 0.1**(steps / s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(steps, lrs, \"-\", linewidth=2)\n",
    "plt.axis([0, n_steps - 1, 0, lr0 * 1.1])\n",
    "plt.xlabel(\"Batch\")\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.title(\"Exponential Scheduling (per batch)\", fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Piecewise Constant Scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def piecewise_constant_fn(epoch):\n",
    "    if epoch < 5:\n",
    "        return 0.01\n",
    "    elif epoch < 15:\n",
    "        return 0.005\n",
    "    else:\n",
    "        return 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def piecewise_constant(boundaries, values):\n",
    "    boundaries = np.array([0] + boundaries)\n",
    "    values = np.array(values)\n",
    "    def piecewise_constant_fn(epoch):\n",
    "        return values[np.argmax(boundaries > epoch) - 1]\n",
    "    return piecewise_constant_fn\n",
    "\n",
    "piecewise_constant_fn = piecewise_constant([5, 15], [0.01, 0.005, 0.001])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = keras.callbacks.LearningRateScheduler(piecewise_constant_fn)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "n_epochs = 25\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid),\n",
    "                    callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.epoch, [piecewise_constant_fn(epoch) for epoch in history.epoch], \"o-\")\n",
    "plt.axis([0, n_epochs - 1, 0, 0.011])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.title(\"Piecewise Constant Scheduling\", fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=5)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "optimizer = keras.optimizers.SGD(lr=0.02, momentum=0.9)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "n_epochs = 25\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid),\n",
    "                    callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.epoch, history.history[\"lr\"], \"bo-\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Learning Rate\", color='b')\n",
    "plt.tick_params('y', colors='b')\n",
    "plt.gca().set_xlim(0, n_epochs - 1)\n",
    "plt.grid(True)\n",
    "\n",
    "ax2 = plt.gca().twinx()\n",
    "ax2.plot(history.epoch, history.history[\"val_loss\"], \"r^-\")\n",
    "ax2.set_ylabel('Validation Loss', color='r')\n",
    "ax2.tick_params('y', colors='r')\n",
    "\n",
    "plt.title(\"Reduce LR on Plateau\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.keras schedulers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "s = 20 * len(X_train) // 32 # number of steps in 20 epochs (batch size = 32)\n",
    "learning_rate = keras.optimizers.schedules.ExponentialDecay(0.01, s, 0.1)\n",
    "optimizer = keras.optimizers.SGD(learning_rate)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "n_epochs = 25\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For piecewise constant scheduling, try this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = keras.optimizers.schedules.PiecewiseConstantDecay(\n",
    "    boundaries=[5. * n_steps_per_epoch, 15. * n_steps_per_epoch],\n",
    "    values=[0.01, 0.005, 0.001])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1Cycle scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = keras.backend\n",
    "\n",
    "class ExponentialLearningRate(keras.callbacks.Callback):\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "        self.rates = []\n",
    "        self.losses = []\n",
    "    def on_batch_end(self, batch, logs):\n",
    "        self.rates.append(K.get_value(self.model.optimizer.lr))\n",
    "        self.losses.append(logs[\"loss\"])\n",
    "        K.set_value(self.model.optimizer.lr, self.model.optimizer.lr * self.factor)\n",
    "\n",
    "def find_learning_rate(model, X, y, epochs=1, batch_size=32, min_rate=10**-5, max_rate=10):\n",
    "    init_weights = model.get_weights()\n",
    "    iterations = len(X) // batch_size * epochs\n",
    "    factor = np.exp(np.log(max_rate / min_rate) / iterations)\n",
    "    init_lr = K.get_value(model.optimizer.lr)\n",
    "    K.set_value(model.optimizer.lr, min_rate)\n",
    "    exp_lr = ExponentialLearningRate(factor)\n",
    "    history = model.fit(X, y, epochs=epochs, batch_size=batch_size,\n",
    "                        callbacks=[exp_lr])\n",
    "    K.set_value(model.optimizer.lr, init_lr)\n",
    "    model.set_weights(init_weights)\n",
    "    return exp_lr.rates, exp_lr.losses\n",
    "\n",
    "def plot_lr_vs_loss(rates, losses):\n",
    "    plt.plot(rates, losses)\n",
    "    plt.gca().set_xscale('log')\n",
    "    plt.hlines(min(losses), min(rates), max(rates))\n",
    "    plt.axis([min(rates), max(rates), min(losses), (losses[0] + min(losses)) / 2])\n",
    "    plt.xlabel(\"Learning rate\")\n",
    "    plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "rates, losses = find_learning_rate(model, X_train_scaled, y_train, epochs=1, batch_size=batch_size)\n",
    "plot_lr_vs_loss(rates, losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneCycleScheduler(keras.callbacks.Callback):\n",
    "    def __init__(self, iterations, max_rate, start_rate=None,\n",
    "                 last_iterations=None, last_rate=None):\n",
    "        self.iterations = iterations\n",
    "        self.max_rate = max_rate\n",
    "        self.start_rate = start_rate or max_rate / 10\n",
    "        self.last_iterations = last_iterations or iterations // 10 + 1\n",
    "        self.half_iteration = (iterations - self.last_iterations) // 2\n",
    "        self.last_rate = last_rate or self.start_rate / 1000\n",
    "        self.iteration = 0\n",
    "    def _interpolate(self, iter1, iter2, rate1, rate2):\n",
    "        return ((rate2 - rate1) * (self.iteration - iter1)\n",
    "                / (iter2 - iter1) + rate1)\n",
    "    def on_batch_begin(self, batch, logs):\n",
    "        if self.iteration < self.half_iteration:\n",
    "            rate = self._interpolate(0, self.half_iteration, self.start_rate, self.max_rate)\n",
    "        elif self.iteration < 2 * self.half_iteration:\n",
    "            rate = self._interpolate(self.half_iteration, 2 * self.half_iteration,\n",
    "                                     self.max_rate, self.start_rate)\n",
    "        else:\n",
    "            rate = self._interpolate(2 * self.half_iteration, self.iterations,\n",
    "                                     self.start_rate, self.last_rate)\n",
    "            rate = max(rate, self.last_rate)\n",
    "        self.iteration += 1\n",
    "        K.set_value(self.model.optimizer.lr, rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 25\n",
    "onecycle = OneCycleScheduler(len(X_train) // batch_size * n_epochs, max_rate=0.05)\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs, batch_size=batch_size,\n",
    "                    validation_data=(X_valid_scaled, y_valid),\n",
    "                    callbacks=[onecycle])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avoiding Overfitting Through Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\ell_1$ and $\\ell_2$ regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = keras.layers.Dense(100, activation=\"elu\",\n",
    "                           kernel_initializer=\"he_normal\",\n",
    "                           kernel_regularizer=keras.regularizers.l2(0.01))\n",
    "# or l1(0.1) for ℓ1 regularization with a factor or 0.1\n",
    "# or l1_l2(0.1, 0.01) for both ℓ1 and ℓ2 regularization, with factors 0.1 and 0.01 respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"elu\",\n",
    "                       kernel_initializer=\"he_normal\",\n",
    "                       kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "    keras.layers.Dense(100, activation=\"elu\",\n",
    "                       kernel_initializer=\"he_normal\",\n",
    "                       kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "    keras.layers.Dense(10, activation=\"softmax\",\n",
    "                       kernel_regularizer=keras.regularizers.l2(0.01))\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "n_epochs = 2\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "RegularizedDense = partial(keras.layers.Dense,\n",
    "                           activation=\"elu\",\n",
    "                           kernel_initializer=\"he_normal\",\n",
    "                           kernel_regularizer=keras.regularizers.l2(0.01))\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    RegularizedDense(300),\n",
    "    RegularizedDense(100),\n",
    "    RegularizedDense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "n_epochs = 2\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(300, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "n_epochs = 2\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alpha Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.AlphaDropout(rate=0.2),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.AlphaDropout(rate=0.2),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.AlphaDropout(rate=0.2),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "optimizer = keras.optimizers.SGD(lr=0.01, momentum=0.9, nesterov=True)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "n_epochs = 20\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MC Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probas = np.stack([model(X_test_scaled, training=True)\n",
    "                     for sample in range(100)])\n",
    "y_proba = y_probas.mean(axis=0)\n",
    "y_std = y_probas.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(model.predict(X_test_scaled[:1]), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(y_probas[:, :1], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(y_proba[:1], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_std = y_probas.std(axis=0)\n",
    "np.round(y_std[:1], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(y_proba, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = np.sum(y_pred == y_test) / len(y_test)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCDropout(keras.layers.Dropout):\n",
    "    def call(self, inputs):\n",
    "        return super().call(inputs, training=True)\n",
    "\n",
    "class MCAlphaDropout(keras.layers.AlphaDropout):\n",
    "    def call(self, inputs):\n",
    "        return super().call(inputs, training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_model = keras.models.Sequential([\n",
    "    MCAlphaDropout(layer.rate) if isinstance(layer, keras.layers.AlphaDropout) else layer\n",
    "    for layer in model.layers\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(lr=0.01, momentum=0.9, nesterov=True)\n",
    "mc_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_model.set_weights(model.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the model with MC Dropout:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(np.mean([mc_model.predict(X_test_scaled[:1]) for sample in range(100)], axis=0), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                           kernel_constraint=keras.constraints.max_norm(1.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MaxNormDense = partial(keras.layers.Dense,\n",
    "                       activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       kernel_constraint=keras.constraints.max_norm(1.))\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    MaxNormDense(300),\n",
    "    MaxNormDense(100),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "n_epochs = 2\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. to 7."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See appendix A."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Deep Learning on CIFAR10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a.\n",
    "*Exercise: Build a DNN with 20 hidden layers of 100 neurons each (that's too many, but it's the point of this exercise). Use He initialization and the ELU activation function.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100,\n",
    "                                 activation=\"elu\",\n",
    "                                 kernel_initializer=\"he_normal\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b.\n",
    "*Exercise: Using Nadam optimization and early stopping, train the network on the CIFAR10 dataset. You can load it with `keras.datasets.cifar10.load_data()`. The dataset is composed of 60,000 32 × 32–pixel color images (50,000 for training, 10,000 for testing) with 10 classes, so you'll need a softmax output layer with 10 neurons. Remember to search for the right learning rate each time you change the model's architecture or hyperparameters.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add the output layer to the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use a Nadam optimizer with a learning rate of 5e-5. I tried learning rates 1e-5, 3e-5, 1e-4, 3e-4, 1e-3, 3e-3 and 1e-2, and I compared their learning curves for 10 epochs each (using the TensorBoard callback, below). The learning rates 3e-5 and 1e-4 were pretty good, so I tried 5e-5, which turned out to be slightly better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Nadam(lr=5e-5)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the CIFAR10 dataset. We also want to use early stopping, so we need a validation set. Let's use the first 5,000 images of the original training set as the validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "X_train = X_train_full[5000:]\n",
    "y_train = y_train_full[5000:]\n",
    "X_valid = X_train_full[:5000]\n",
    "y_valid = y_train_full[:5000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create the callbacks we need and train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_cifar10_model.h5\", save_best_only=True)\n",
    "run_index = 1 # increment every time you train the model\n",
    "run_logdir = os.path.join(os.curdir, \"my_cifar10_logs\", \"run_{:03d}\".format(run_index))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir=./my_cifar10_logs --port=6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs=100,\n",
    "          validation_data=(X_valid, y_valid),\n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_cifar10_model.h5\")\n",
    "model.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model with the lowest validation loss gets about 47% accuracy on the validation set. It took 39 epochs to reach the lowest validation loss, with roughly 10 seconds per epoch on my laptop (without a GPU). Let's see if we can improve performance using Batch Normalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c.\n",
    "*Exercise: Now try adding Batch Normalization and compare the learning curves: Is it converging faster than before? Does it produce a better model? How does it affect training speed?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below is very similar to the code above, with a few changes:\n",
    "\n",
    "* I added a BN layer after every Dense layer (before the activation function), except for the output layer. I also added a BN layer before the first hidden layer.\n",
    "* I changed the learning rate to 5e-4. I experimented with 1e-5, 3e-5, 5e-5, 1e-4, 3e-4, 5e-4, 1e-3 and 3e-3, and I chose the one with the best validation performance after 20 epochs.\n",
    "* I renamed the run directories to run_bn_* and the model file name to my_cifar10_bn_model.h5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100, kernel_initializer=\"he_normal\"))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Activation(\"elu\"))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(lr=5e-4)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_cifar10_bn_model.h5\", save_best_only=True)\n",
    "run_index = 1 # increment every time you train the model\n",
    "run_logdir = os.path.join(os.curdir, \"my_cifar10_logs\", \"run_bn_{:03d}\".format(run_index))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]\n",
    "\n",
    "model.fit(X_train, y_train, epochs=100,\n",
    "          validation_data=(X_valid, y_valid),\n",
    "          callbacks=callbacks)\n",
    "\n",
    "model = keras.models.load_model(\"my_cifar10_bn_model.h5\")\n",
    "model.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *Is the model converging faster than before?* Much faster! The previous model took 39 epochs to reach the lowest validation loss, while the new model with BN took 18 epochs. That's more than twice as fast as the previous model. The BN layers stabilized training and allowed us to use a much larger learning rate, so convergence was faster.\n",
    "* *Does BN produce a better model?* Yes! The final model is also much better, with 55% accuracy instead of 47%. It's still not a very good model, but at least it's much better than before (a Convolutional Neural Network would do much better, but that's a different topic, see chapter 14).\n",
    "* *How does BN affect training speed?* Although the model converged twice as fast, each epoch took about 16s instead of 10s, because of the extra computations required by the BN layers. So overall, although the number of epochs was reduced by 50%, the training time (wall time) was shortened by 30%. Which is still pretty significant!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d.\n",
    "*Exercise: Try replacing Batch Normalization with SELU, and make the necessary adjustements to ensure the network self-normalizes (i.e., standardize the input features, use LeCun normal initialization, make sure the DNN contains only a sequence of dense layers, etc.).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100,\n",
    "                                 kernel_initializer=\"lecun_normal\",\n",
    "                                 activation=\"selu\"))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(lr=7e-4)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_cifar10_selu_model.h5\", save_best_only=True)\n",
    "run_index = 1 # increment every time you train the model\n",
    "run_logdir = os.path.join(os.curdir, \"my_cifar10_logs\", \"run_selu_{:03d}\".format(run_index))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]\n",
    "\n",
    "X_means = X_train.mean(axis=0)\n",
    "X_stds = X_train.std(axis=0)\n",
    "X_train_scaled = (X_train - X_means) / X_stds\n",
    "X_valid_scaled = (X_valid - X_means) / X_stds\n",
    "X_test_scaled = (X_test - X_means) / X_stds\n",
    "\n",
    "model.fit(X_train_scaled, y_train, epochs=100,\n",
    "          validation_data=(X_valid_scaled, y_valid),\n",
    "          callbacks=callbacks)\n",
    "\n",
    "model = keras.models.load_model(\"my_cifar10_selu_model.h5\")\n",
    "model.evaluate(X_valid_scaled, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_cifar10_selu_model.h5\")\n",
    "model.evaluate(X_valid_scaled, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get 51.4% accuracy, which is better than the original model, but not quite as good as the model using batch normalization. Moreover, it took 13 epochs to reach the best model, which is much faster than both the original model and the BN model, plus each epoch took only 10 seconds, just like the original model. So it's by far the fastest model to train (both in terms of epochs and wall time)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e.\n",
    "*Exercise: Try regularizing the model with alpha dropout. Then, without retraining your model, see if you can achieve better accuracy using MC Dropout.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100,\n",
    "                                 kernel_initializer=\"lecun_normal\",\n",
    "                                 activation=\"selu\"))\n",
    "\n",
    "model.add(keras.layers.AlphaDropout(rate=0.1))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(lr=5e-4)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_cifar10_alpha_dropout_model.h5\", save_best_only=True)\n",
    "run_index = 1 # increment every time you train the model\n",
    "run_logdir = os.path.join(os.curdir, \"my_cifar10_logs\", \"run_alpha_dropout_{:03d}\".format(run_index))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]\n",
    "\n",
    "X_means = X_train.mean(axis=0)\n",
    "X_stds = X_train.std(axis=0)\n",
    "X_train_scaled = (X_train - X_means) / X_stds\n",
    "X_valid_scaled = (X_valid - X_means) / X_stds\n",
    "X_test_scaled = (X_test - X_means) / X_stds\n",
    "\n",
    "model.fit(X_train_scaled, y_train, epochs=100,\n",
    "          validation_data=(X_valid_scaled, y_valid),\n",
    "          callbacks=callbacks)\n",
    "\n",
    "model = keras.models.load_model(\"my_cifar10_alpha_dropout_model.h5\")\n",
    "model.evaluate(X_valid_scaled, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model reaches 50.8% accuracy on the validation set. That's very slightly worse than without dropout (51.4%). With an extensive hyperparameter search, it might be possible to do better (I tried dropout rates of 5%, 10%, 20% and 40%, and learning rates 1e-4, 3e-4, 5e-4, and 1e-3), but probably not much better in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use MC Dropout now. We will need the `MCAlphaDropout` class we used earlier, so let's just copy it here for convenience:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCAlphaDropout(keras.layers.AlphaDropout):\n",
    "    def call(self, inputs):\n",
    "        return super().call(inputs, training=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create a new model, identical to the one we just trained (with the same weights), but with `MCAlphaDropout` dropout layers instead of `AlphaDropout` layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_model = keras.models.Sequential([\n",
    "    MCAlphaDropout(layer.rate) if isinstance(layer, keras.layers.AlphaDropout) else layer\n",
    "    for layer in model.layers\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then let's add a couple utility functions. The first will run the model many times (10 by default) and it will return the mean predicted class probabilities. The second will use these mean probabilities to predict the most likely class for each instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mc_dropout_predict_probas(mc_model, X, n_samples=10):\n",
    "    Y_probas = [mc_model.predict(X) for sample in range(n_samples)]\n",
    "    return np.mean(Y_probas, axis=0)\n",
    "\n",
    "def mc_dropout_predict_classes(mc_model, X, n_samples=10):\n",
    "    Y_probas = mc_dropout_predict_probas(mc_model, X, n_samples)\n",
    "    return np.argmax(Y_probas, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's make predictions for all the instances in the validation set, and compute the accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "y_pred = mc_dropout_predict_classes(mc_model, X_valid_scaled)\n",
    "accuracy = np.mean(y_pred == y_valid[:, 0])\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only get virtually no accuracy improvement in this case (from 50.8% to 50.9%).\n",
    "\n",
    "So the best model we got in this exercise is the Batch Normalization model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f.\n",
    "*Exercise: Retrain your model using 1cycle scheduling and see if it improves training speed and model accuracy.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100,\n",
    "                                 kernel_initializer=\"lecun_normal\",\n",
    "                                 activation=\"selu\"))\n",
    "\n",
    "model.add(keras.layers.AlphaDropout(rate=0.1))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "optimizer = keras.optimizers.SGD(lr=1e-3)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "rates, losses = find_learning_rate(model, X_train_scaled, y_train, epochs=1, batch_size=batch_size)\n",
    "plot_lr_vs_loss(rates, losses)\n",
    "plt.axis([min(rates), max(rates), min(losses), (losses[0] + min(losses)) / 1.4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100,\n",
    "                                 kernel_initializer=\"lecun_normal\",\n",
    "                                 activation=\"selu\"))\n",
    "\n",
    "model.add(keras.layers.AlphaDropout(rate=0.1))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "optimizer = keras.optimizers.SGD(lr=1e-2)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 15\n",
    "onecycle = OneCycleScheduler(len(X_train_scaled) // batch_size * n_epochs, max_rate=0.05)\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs, batch_size=batch_size,\n",
    "                    validation_data=(X_valid_scaled, y_valid),\n",
    "                    callbacks=[onecycle])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One cycle allowed us to train the model in just 15 epochs, each taking only 3 seconds (thanks to the larger batch size). This is over 3 times faster than the fastest model we trained so far. Moreover, we improved the model's performance (from 50.8% to 52.8%). The batch normalized model reaches a slightly better performance, but it's much slower to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "nav_menu": {
   "height": "360px",
   "width": "416px"
  },
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
