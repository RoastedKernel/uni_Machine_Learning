{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "import tarfile\n",
    "import urllib\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Google_Stock_Price_Train.csv\")\n",
    "data_test = pd.read_csv(\"Google_Stock_Price_Test.csv\")\n",
    "data_Open = data.loc[:,[\"Open\"]].values\n",
    "data_test_Open = data_test.loc[:,[\"Open\"]].values\n",
    "train = data_Open[:len(data)-200] \n",
    "valid = data_Open[len(train):] \n",
    "train = train.reshape(train.shape[0],1)\n",
    "valid = valid.reshape(valid.shape[0],1)\n",
    "test = data_test_Open.reshape(data_test_Open.shape[0],1)\n",
    "scaler = MinMaxScaler(feature_range= (0,1)) # defining of Scaler\n",
    "train_scaled = scaler.fit_transform(train) # applying to Scaler to train\n",
    "test_scaled = scaler.transform(test)\n",
    "valid_scaled = scaler.transform(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid = []\n",
    "y_valid = []\n",
    "timesteps = 120\n",
    "\n",
    "for i in range(timesteps, valid_scaled.shape[0]):\n",
    "    X_valid.append(valid_scaled[i-timesteps:i,0])\n",
    "    y_valid.append(valid_scaled[i,0])\n",
    "\n",
    "X_valid, y_valid = np.array(X_valid), np.array(y_valid)\n",
    "\n",
    "\n",
    "# Reshaping\n",
    "X_valid = X_valid.reshape(X_valid.shape[0], X_valid.shape[1], 1)  # Dimension of array is 3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "#timesteps = 50\n",
    "\n",
    "for i in range(timesteps, train_scaled.shape[0]):\n",
    "    X_train.append(train_scaled[i-timesteps:i,0])\n",
    "    y_train.append(train_scaled[i,0])\n",
    "\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "\n",
    "\n",
    "# Reshaping\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)  # Dimension of array is 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_total = pd.concat((data['Open'], data_test['Open']), axis = 0)\n",
    "inputs = dataset_total[len(dataset_total) - len(data_test) - timesteps:].values\n",
    "inputs = inputs.reshape(-1,1)\n",
    "inputs = scaler.transform(inputs)\n",
    "X_test = []\n",
    "for i in range(timesteps, inputs.shape[0]):\n",
    "    X_test.append(inputs[i-timesteps:i, 0])\n",
    "X_test = np.array(X_test)\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "\n",
    "     'method': 'grid',\n",
    "\n",
    "    'parameters': {\n",
    "        'units': \n",
    "         {'values': [20,30,40,50,60,80,120,150]},\n",
    "        \n",
    "        'Drop_1': \n",
    "            {'values': [ 0.1,0.2,0.25,0.3]\n",
    "                   \n",
    "                   \n",
    "                },\n",
    "        \n",
    "        'Drop_2': \n",
    "            {'values': [ 0.1,0.2,0.3,0.4,0.5]\n",
    "                   \n",
    "                   \n",
    "                }\n",
    "     \n",
    "    \n",
    "        }\n",
    "\n",
    "    }\n",
    "sweep_id = wandb.sweep(sweep_config, project= \"LSTM_4Layers\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    from tensorflow.keras.models import Sequential  \n",
    "    from tensorflow.keras.layers import Dense \n",
    "    from tensorflow.keras.layers import SimpleRNN\n",
    "    from tensorflow.keras.layers import LSTM\n",
    "    from tensorflow.keras.layers import Dropout # it block to overfitting \n",
    "    from tensorflow.keras.optimizers import Adam\n",
    "    from tensorflow.keras.callbacks import EarlyStopping\n",
    "    from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "    wandb.init()\n",
    "    configs = {'units': 80,'Drop_1': 0.25, 'Drop_2': 0.5}\n",
    "    config = wandb.config\n",
    "    config.epochs = 2000\n",
    "    config.Batchsize = 256\n",
    "    \n",
    "    \n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units = wandb.config.units,return_sequences = True,input_shape = (X_train.shape[1],1)))\n",
    "    model.add(Dropout(wandb.config.Drop_1))\n",
    "\n",
    "    model.add(LSTM(units = wandb.config.units,return_sequences = True))\n",
    "    model.add(Dropout(wandb.config.Drop_1))\n",
    "\n",
    "    model.add(LSTM(units = wandb.config.units,return_sequences = True))\n",
    "    model.add(Dropout(wandb.config.Drop_1))\n",
    "\n",
    "\n",
    "    model.add(LSTM(units = wandb.config.units))\n",
    "    model.add(Dropout(wandb.config.Drop_2))\n",
    "\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    es = EarlyStopping(monitor= 'val_loss', mode='min', patience=200)\n",
    "\n",
    "#     metric = \"val_accuracy\"\n",
    "\n",
    "    modelsave = ModelCheckpoint(\"LSTM_best.h5\", monitor= 'val_loss', verbose=1, save_best_only=True,\n",
    "                             save_weights_only=False, mode='min')\n",
    "    \n",
    "    \n",
    "    #n_epochs = 100\n",
    "    batch = 256\n",
    "    #opt = Adam(lr=wandb.config.learning_rate,amsgrad=True)\n",
    "    \n",
    "    #opt = Adam(learning_rate=3e-3 , beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=True)\n",
    "    model.compile(loss='mean_squared_error', optimizer=\"Adam\")\n",
    "    \n",
    "    wandb_callback = WandbCallback(validation_data=(X_valid, y_valid))\n",
    "\n",
    "    History_LSTM = model.fit(X_train, y_train, epochs=wandb.config.epochs,validation_data=(X_valid, y_valid)\n",
    "                         , batch_size=wandb.config.Batchsize,shuffle=False\n",
    "                             , callbacks=[es,modelsave,wandb_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.agent(sweep_id, function=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
