{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "# from tensorflow.keras import datasets, layers, models\n",
    "# from tensorflow.keras.callbacks import EarlyStopping\n",
    "# from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "# from tensorflow.keras.models import Sequential, Model\n",
    "# from tensorflow.keras.layers import BatchNormalization, Conv2D, MaxPooling2D, Flatten, Dense, AveragePooling2D\n",
    "# from tensorflow.keras.layers import ZeroPadding2D, add, Input, Activation\n",
    "# from tensorflow.keras.regularizers import l2\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "# from tensorflow.keras.optimizers import SGD\n",
    "# from tensorflow.keras.optimizers import Adam , Adadelta, RMSprop, Nadam\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "# from tensorflow.keras import backend as K\n",
    "# from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import wandb\n",
    "import mxnet as mx\n",
    "from wandb.keras import WandbCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((trainX, trainY), (testX, testY)) = cifar10.load_data()\n",
    "\n",
    "trainX = trainX.astype(\"float\") / 255.0\n",
    "testX = testX.astype(\"float\") / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelBinarizer()\n",
    "trainY = lb.fit_transform(trainY)\n",
    "testY = lb.transform(testY)\n",
    "\n",
    "labelNames = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\",\n",
    "\"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squeeze(input, numFilter):\n",
    "# the first part of a FIRE module consists of a number of 1x1\n",
    "# filter squeezes on the input data followed by an activation\n",
    "    squeeze_1x1 = mx.sym.Convolution(data=input, kernel=(1, 1),\n",
    "    stride=(1, 1), num_filter=numFilter)\n",
    "    act_1x1 = mx.sym.LeakyReLU(data=squeeze_1x1,\n",
    "    act_type=\"elu\")\n",
    "    return act_1x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fire(input, numSqueezeFilter, numExpandFilter):\n",
    "    squeeze_1x1 = squeeze(input, numSqueezeFilter)\n",
    "    expand_1x1 = mx.sym.Convolution(data=squeeze_1x1,\n",
    "                kernel=(1, 1), stride=(1, 1), num_filter=numExpandFilter)\n",
    "    relu_expand_1x1 = mx.sym.LeakyReLU(data=expand_1x1,\n",
    "                act_type=\"elu\")\n",
    "    expand_3x3 = mx.sym.Convolution(data=squeeze_1x1, pad=(1, 1),\n",
    "                kernel=(3, 3), stride=(1, 1), num_filter=numExpandFilter)\n",
    "    relu_expand_3x3 = mx.sym.LeakyReLU(data=expand_3x3,\n",
    "                act_type=\"elu\")\n",
    "    output = mx.sym.Concat(relu_expand_1x1, relu_expand_3x3,\n",
    "                dim=1)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build(classes):\n",
    "     # data input\n",
    "    data = mx.sym.Variable(\"data\")\n",
    "\n",
    "    # Block #1: CONV => RELU => POOL\n",
    "    conv_1 = mx.sym.Convolution(data=data, kernel=(2, 2),\n",
    "        stride=(1, 1), num_filter=64)\n",
    "    relu_1 = mx.sym.LeakyReLU(data=conv_1, act_type=\"elu\")\n",
    "    pool_1 = mx.sym.Pooling(data=relu_1, kernel=(3, 3),\n",
    "        stride=(1, 1), pool_type=\"max\")\n",
    "\n",
    "    # Block #2-4: (FIRE * 3) => POOL\n",
    "    fire_2 = fire(pool_1, numSqueezeFilter=16,\n",
    "        numExpandFilter=32)\n",
    "    fire_3 = fire(fire_2, numSqueezeFilter=16,\n",
    "        numExpandFilter=32)\n",
    "    fire_4 = fire(fire_3, numSqueezeFilter=32,\n",
    "         numExpandFilter=64)\n",
    "    pool_4 = mx.sym.Pooling(data=fire_4, kernel=(3, 3),\n",
    "        stride=(2, 2), pool_type=\"max\")\n",
    "\n",
    "    # Block #5-8: (FIRE * 4) => POOL\n",
    "    fire_5 = fire(pool_4, numSqueezeFilter=32,\n",
    "        numExpandFilter=128)\n",
    "    fire_6 = fire(fire_5, numSqueezeFilter=48,\n",
    "        numExpandFilter=192)\n",
    "    fire_7 = fire(fire_6, numSqueezeFilter=48,\n",
    "        numExpandFilter=192)\n",
    "    fire_8 = fire(fire_7, numSqueezeFilter=64,\n",
    "        numExpandFilter=256)\n",
    "    pool_8 = mx.sym.Pooling(data=fire_8, kernel=(3, 3),\n",
    "        stride=(1, 1), pool_type=\"max\")\n",
    "\n",
    "            # Block #9-10: FIRE => DROPOUT => CONV => RELU => POOL\n",
    "    fire_9 = fire(pool_8, numSqueezeFilter=32,\n",
    "        numExpandFilter=128)\n",
    "    do_9 = mx.sym.Dropout(data=fire_9, p=0.5)\n",
    "    conv_10 = mx.sym.Convolution(data=do_9, num_filter=classes,\n",
    "        kernel=(1, 1), stride=(1, 1))\n",
    "    relu_10 = mx.sym.LeakyReLU(data=conv_10, act_type=\"elu\")\n",
    "    pool_10 = mx.sym.Pooling(data=relu_10, kernel=(12, 12),\n",
    "        pool_type=\"avg\"\n",
    "            # softmax classifier\n",
    "    flatten = mx.sym.Flatten(data=pool_10)\n",
    "    model = mx.sym.SoftmaxOutput(data=flatten, name=\"softmax\")\n",
    "\n",
    "    # return the network architecture\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "\n",
    "trainIter = mx.io.ImageRecordIter( path_imgrec=(trainX, trainY), data_shape=(227, 227,3)\n",
    "                                  , batch_size=batchSize, rand_crop=True,\n",
    "                                  rand_mirror=True, rotate=15, max_shear_ratio=0.1)\n",
    "\n",
    "valIter = mx.io.ImageRecordIter(path_imgrec=(testX, testY), data_shape=(227, 227,3),\n",
    "                                batch_size=batchSize)\n",
    "\n",
    "metrics = [mx.metric.Accuracy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = mx.optimizer.SGD(learning_rate=1e-2, momentum=0.9, wd=0.0002,\n",
    "rescale_grad=1.0 / batchSize)\n",
    "\n",
    "model = build(10)\n",
    "model = model.symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mx.model.FeedForward(ctx=[mx.gpu(0)],symbol=model,\n",
    "initializer=mx.initializer.Xavier(),arg_params=argParams,\n",
    "aux_params=auxParams,optimizer=opt,num_epoch=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X=trainIter, eval_data=valIter, eval_metric=metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
