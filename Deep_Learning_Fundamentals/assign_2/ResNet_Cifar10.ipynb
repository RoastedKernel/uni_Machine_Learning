{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import BatchNormalization, Conv2D, MaxPooling2D, Flatten, Dense, AveragePooling2D\n",
    "from tensorflow.keras.layers import ZeroPadding2D, add, Input, Activation\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "((trainX, trainY), (testX, testY)) = cifar10.load_data()\n",
    "\n",
    "trainX = trainX.astype(\"float\") / 255.0\n",
    "testX = testX.astype(\"float\") / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelBinarizer()\n",
    "trainY = lb.fit_transform(trainY)\n",
    "testY = lb.transform(testY)\n",
    "\n",
    "labelNames = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\",\n",
    "\"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_module(data, K, stride, chanDim,\n",
    "                    reg=0.0001, bnEps=2e-5, bnMom=0.9, reduce=False):\n",
    "    \n",
    "    shortcut = data\n",
    "    \n",
    "    bn1 = BatchNormalization(axis=chanDim, epsilon=bnEps,\n",
    "            momentum=bnMom)(data)\n",
    "    act1 = Activation(\"relu\")(bn1)\n",
    "    \n",
    "    conv1 = Conv2D(int(K * 0.25), (1, 1), use_bias=False,\n",
    "                kernel_regularizer=l2(reg))(act1)\n",
    "    \n",
    "    \n",
    "    bn2 = BatchNormalization(axis=chanDim, epsilon=bnEps,\n",
    "                momentum=bnMom)(conv1)\n",
    "    act2 = Activation(\"relu\")(bn2)\n",
    "    conv2 = Conv2D(int(K * 0.25), (3, 3), strides=stride,\n",
    "                padding=\"same\", use_bias=False,\n",
    "    kernel_regularizer=l2(reg))(act2)\n",
    "    \n",
    "    \n",
    "    bn3 = BatchNormalization(axis=chanDim, epsilon=bnEps,\n",
    "                momentum=bnMom)(conv2)\n",
    "    act3 = Activation(\"relu\")(bn3)\n",
    "    conv3 = Conv2D(K, (1, 1), use_bias=False,\n",
    "                kernel_regularizer=l2(reg))(act3)\n",
    "    \n",
    "    \n",
    "    \n",
    "    if reduce:\n",
    "        shortcut = Conv2D(K, (1, 1), strides=stride,\n",
    "            use_bias=False, kernel_regularizer=l2(reg))(act1)\n",
    "    \n",
    "    x = add([conv3, shortcut])\n",
    "    \n",
    "    \n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_Resnet(width, height, depth, classes, stages, filters,\n",
    "                reg=0.0001, bnEps=2e-5, bnMom=0.9):\n",
    "    \n",
    "    \n",
    "    inputShape = (height, width, depth)\n",
    "    chanDim = -1\n",
    "    inputs = Input(shape=inputShape)\n",
    "    x = BatchNormalization(axis=chanDim, epsilon=bnEps,\n",
    "                            momentum=bnMom)(inputs)\n",
    "    x = Conv2D(filters[0], (3, 3), use_bias=False,padding=\"same\", kernel_regularizer=l2(reg))(x)\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in range(0, len(stages)):\n",
    "\n",
    "        stride = (1, 1) if i == 0 else (2, 2)\n",
    "        \n",
    "        x = residual_module(x, filters[i + 1], stride,\n",
    "                chanDim, reduce=True, bnEps=bnEps, bnMom=bnMom)\n",
    "        \n",
    "        for j in range(0, stages[i] - 1):\n",
    "            \n",
    "            x = residual_module(x, filters[i + 1],\n",
    "                    (1, 1), chanDim, bnEps=bnEps, bnMom=bnMom)\n",
    "            \n",
    "    x = BatchNormalization(axis=chanDim, epsilon=bnEps,\n",
    "                            momentum=bnMom)(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = AveragePooling2D((8, 8))(x) \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(classes, kernel_regularizer=l2(reg))(x)\n",
    "    x = Activation(\"softmax\")(x)\n",
    "    \n",
    "    model = Model(inputs, x, name=\"resnet\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 100\n",
    "INIT_LR = 1e-2\n",
    "\n",
    "def poly_decay(epoch):\n",
    "    maxEpochs = NUM_EPOCHS\n",
    "    baseLR = INIT_LR\n",
    "    power = 1.0\n",
    "    alpha = baseLR * (1 - (epoch / float(maxEpochs))) ** power\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_Resnet(32, 32, 3, 10, (9, 9, 9),\n",
    "                                (64, 64, 128, 256), reg=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "Batch_size = 512\n",
    "lr = 0.01\n",
    "epochs = 100\n",
    "\n",
    "callbacks = [LearningRateScheduler(poly_decay)]\n",
    "\n",
    "\n",
    "opt = SGD(lr= lr, momentum= 0.9, nesterov=True)\n",
    "#opt = SGD(lr= lr ,decay = ,  momentum= 0.9, nesterov=True)\n",
    "#\n",
    "#opt = Adam(lr=lr,amsgrad=True)\n",
    "\n",
    "\n",
    "# s = 10 * len(trainX) // Batch_size # number of steps in 20 epochs (batch size = 32)\n",
    "# learning_rate0 = keras.optimizers.schedules.ExponentialDecay(0.01, s, 0.1)\n",
    "\n",
    "# opt = Adam(learning_rate0,amsgrad=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
    "metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "98/98 [==============================] - 25s 252ms/step - loss: 2.4239 - accuracy: 0.2664 - val_loss: 2.2282 - val_accuracy: 0.3396 - lr: 0.0100\n",
      "Epoch 2/100\n",
      "98/98 [==============================] - 24s 243ms/step - loss: 2.1004 - accuracy: 0.3863 - val_loss: 2.1996 - val_accuracy: 0.3715 - lr: 0.0099\n",
      "Epoch 3/100\n",
      "98/98 [==============================] - 24s 241ms/step - loss: 1.9607 - accuracy: 0.4440 - val_loss: 1.8986 - val_accuracy: 0.4669 - lr: 0.0098\n",
      "Epoch 4/100\n",
      "98/98 [==============================] - 24s 241ms/step - loss: 1.8359 - accuracy: 0.4965 - val_loss: 1.8252 - val_accuracy: 0.5039 - lr: 0.0097\n",
      "Epoch 5/100\n",
      "98/98 [==============================] - 24s 242ms/step - loss: 1.7294 - accuracy: 0.5380 - val_loss: 1.7127 - val_accuracy: 0.5401 - lr: 0.0096\n",
      "Epoch 6/100\n",
      "98/98 [==============================] - 24s 241ms/step - loss: 1.6355 - accuracy: 0.5761 - val_loss: 1.6526 - val_accuracy: 0.5637 - lr: 0.0095\n",
      "Epoch 7/100\n",
      "98/98 [==============================] - 24s 242ms/step - loss: 1.5521 - accuracy: 0.6086 - val_loss: 1.6147 - val_accuracy: 0.5777 - lr: 0.0094\n",
      "Epoch 8/100\n",
      "98/98 [==============================] - 24s 242ms/step - loss: 1.4768 - accuracy: 0.6348 - val_loss: 1.5861 - val_accuracy: 0.6074 - lr: 0.0093\n",
      "Epoch 9/100\n",
      "98/98 [==============================] - 24s 243ms/step - loss: 1.4074 - accuracy: 0.6597 - val_loss: 1.5358 - val_accuracy: 0.6121 - lr: 0.0092\n",
      "Epoch 10/100\n",
      "98/98 [==============================] - 24s 247ms/step - loss: 1.3439 - accuracy: 0.6831 - val_loss: 1.5165 - val_accuracy: 0.6228 - lr: 0.0091\n",
      "Epoch 11/100\n",
      "98/98 [==============================] - 24s 242ms/step - loss: 1.2891 - accuracy: 0.7039 - val_loss: 1.4807 - val_accuracy: 0.6394 - lr: 0.0090\n",
      "Epoch 12/100\n",
      "98/98 [==============================] - 24s 244ms/step - loss: 1.2277 - accuracy: 0.7268 - val_loss: 1.5318 - val_accuracy: 0.6210 - lr: 0.0089\n",
      "Epoch 13/100\n",
      "98/98 [==============================] - 24s 241ms/step - loss: 1.1754 - accuracy: 0.7480 - val_loss: 1.5255 - val_accuracy: 0.6316 - lr: 0.0088\n",
      "Epoch 14/100\n",
      "98/98 [==============================] - 24s 247ms/step - loss: 1.1263 - accuracy: 0.7643 - val_loss: 1.4827 - val_accuracy: 0.6482 - lr: 0.0087\n",
      "Epoch 15/100\n",
      "98/98 [==============================] - 24s 244ms/step - loss: 1.0733 - accuracy: 0.7831 - val_loss: 1.5094 - val_accuracy: 0.6421 - lr: 0.0086\n",
      "Epoch 16/100\n",
      "98/98 [==============================] - 24s 246ms/step - loss: 1.0272 - accuracy: 0.7991 - val_loss: 1.6770 - val_accuracy: 0.5996 - lr: 0.0085\n",
      "Epoch 17/100\n",
      "98/98 [==============================] - 24s 242ms/step - loss: 0.9873 - accuracy: 0.8140 - val_loss: 1.6436 - val_accuracy: 0.6320 - lr: 0.0084\n",
      "Epoch 18/100\n",
      "98/98 [==============================] - 24s 242ms/step - loss: 0.9483 - accuracy: 0.8284 - val_loss: 1.6303 - val_accuracy: 0.6380 - lr: 0.0083\n",
      "Epoch 19/100\n",
      "98/98 [==============================] - 24s 245ms/step - loss: 0.8963 - accuracy: 0.8486 - val_loss: 1.6071 - val_accuracy: 0.6429 - lr: 0.0082\n",
      "Epoch 20/100\n",
      "98/98 [==============================] - 24s 242ms/step - loss: 0.8568 - accuracy: 0.8617 - val_loss: 1.8296 - val_accuracy: 0.6183 - lr: 0.0081\n",
      "Epoch 21/100\n",
      "98/98 [==============================] - 24s 243ms/step - loss: 0.8092 - accuracy: 0.8802 - val_loss: 1.7134 - val_accuracy: 0.6432 - lr: 0.0080\n",
      "Epoch 22/100\n",
      "98/98 [==============================] - 24s 245ms/step - loss: 0.7842 - accuracy: 0.8887 - val_loss: 1.6700 - val_accuracy: 0.6584 - lr: 0.0079\n",
      "Epoch 23/100\n",
      "98/98 [==============================] - 24s 242ms/step - loss: 0.7510 - accuracy: 0.8998 - val_loss: 1.8784 - val_accuracy: 0.6279 - lr: 0.0078\n",
      "Epoch 24/100\n",
      "98/98 [==============================] - 24s 245ms/step - loss: 0.7242 - accuracy: 0.9089 - val_loss: 1.7483 - val_accuracy: 0.6458 - lr: 0.0077\n",
      "Epoch 25/100\n",
      "98/98 [==============================] - 24s 244ms/step - loss: 0.6859 - accuracy: 0.9230 - val_loss: 1.8699 - val_accuracy: 0.6387 - lr: 0.0076\n",
      "Epoch 26/100\n",
      "98/98 [==============================] - 24s 247ms/step - loss: 0.6748 - accuracy: 0.9261 - val_loss: 1.7706 - val_accuracy: 0.6562 - lr: 0.0075\n",
      "Epoch 27/100\n",
      "98/98 [==============================] - 24s 245ms/step - loss: 0.6433 - accuracy: 0.9376 - val_loss: 2.0728 - val_accuracy: 0.6125 - lr: 0.0074\n",
      "Epoch 28/100\n",
      "98/98 [==============================] - 24s 244ms/step - loss: 0.6211 - accuracy: 0.9461 - val_loss: 1.9647 - val_accuracy: 0.6496 - lr: 0.0073\n",
      "Epoch 29/100\n",
      "38/98 [==========>...................] - ETA: 13s - loss: 0.5908 - accuracy: 0.9589"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-166-06d86376fe28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m Resnet = model.fit(trainX, trainY, validation_data = (testX, testY)\n\u001b[0m\u001b[1;32m      2\u001b[0m                        \u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                    , verbose= 1)\n",
      "\u001b[0;32m~/miniconda3/envs/ML_CV/lib/python3.8/site-packages/wandb/keras/__init__.py\u001b[0m in \u001b[0;36mnew_v2\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcbk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcbks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0mset_wandb_attrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcbk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mold_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0mtraining_arrays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morig_fit_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ML_CV/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ML_CV/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    853\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m         \u001b[0mepoch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ML_CV/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    387\u001b[0m     \"\"\"\n\u001b[1;32m    388\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ML_CV/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_process_logs\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;34m\"\"\"Turns tensors into numpy arrays or Python scalars.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ML_CV/lib/python3.8/site-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ML_CV/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ML_CV/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ML_CV/lib/python3.8/site-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    517\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ML_CV/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    959\u001b[0m     \"\"\"\n\u001b[1;32m    960\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 961\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    962\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ML_CV/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    925\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 927\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    928\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Resnet = model.fit(trainX, trainY, validation_data = (testX, testY)\n",
    "                       , batch_size = Batch_size, epochs= epochs, callbacks=callbacks\n",
    "                   , verbose= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "# plt.plot(np.arange(0,31),history.history['accuracy'], color='orange')\n",
    "# plt.plot(np.arange(0,31),history.history['loss'],'b')\n",
    "# plt.plot(np.arange(0,31)+0.5,history.history['val_accuracy'],'r')  # offset both validation curves\n",
    "# plt.plot(np.arange(0,31)+0.5,history.history['val_loss'],'g')\n",
    "plt.plot(Resnet.history['accuracy'],color='orange')\n",
    "plt.plot(Resnet.history['val_accuracy'],'r')\n",
    "plt.plot(Resnet.history['loss'],'b')\n",
    "plt.plot(Resnet.history['val_loss'],'g')\n",
    "plt.legend(['Train Acc','Val Acc','Train Loss','Val Loss'])\n",
    "#plt.grid()\n",
    "plt.gca().set_ylim(0, 2.5) # set the vertical range to [0-1] \n",
    "plt.title(\"Resnet \")\n",
    "plt.savefig(\"Resnet\", dpi=300,  bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
