{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "# from tensorflow.keras import datasets, layers, models\n",
    "# from tensorflow.keras.callbacks import EarlyStopping\n",
    "# from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "# from tensorflow.keras.models import Sequential, Model\n",
    "# from tensorflow.keras.layers import BatchNormalization, Conv2D, MaxPooling2D, Flatten, Dense, AveragePooling2D\n",
    "# from tensorflow.keras.layers import ZeroPadding2D, add, Input, Activation\n",
    "# from tensorflow.keras.regularizers import l2\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "# from tensorflow.keras.optimizers import SGD\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# from tensorflow.keras import backend as K\n",
    "# import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "# import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "# tf.config.optimizer.set_jit(True)\n",
    "# policy = mixed_precision.Policy('mixed_float16')\n",
    "# mixed_precision.set_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Compute dtype: %s' % policy.compute_dtype)\n",
    "# print('Variable dtype: %s' % policy.variable_dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "((trainX, trainY), (testX, testY)) = cifar10.load_data()\n",
    "\n",
    "trainX = trainX.astype(\"float\") / 255.0\n",
    "testX = testX.astype(\"float\") / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelBinarizer()\n",
    "trainY = lb.fit_transform(trainY)\n",
    "testY = lb.transform(testY)\n",
    "\n",
    "labelNames = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\",\n",
    "\"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = ImageDataGenerator(width_shift_range=0.1,\n",
    "                height_shift_range=0.1, horizontal_flip=True,fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: vv5ax67l\n",
      "Sweep URL: https://app.wandb.ai/roastedkernel/ResNet_Cifar10_HyperParam_Adam/sweeps/vv5ax67l\n"
     ]
    }
   ],
   "source": [
    "sweep_config = {\n",
    "\n",
    "     'method': 'grid',\n",
    "\n",
    "    'parameters': {\n",
    "        'learning_rate': \n",
    "         {'values': [ 2e-2]},\n",
    "        \n",
    "        'reg': \n",
    "            {'values': [0.05 ,0.04, 0.01]},\n",
    "        \n",
    "        'decay': \n",
    "            {'values': [0.004,0.008,0.006]}\n",
    "     \n",
    "    \n",
    "        }\n",
    "\n",
    "    }\n",
    "sweep_id = wandb.sweep(sweep_config, project= \"ResNet_Cifar10_HyperParam_Adam\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def residual_module(data, K, stride, chanDim,\n",
    "#                     reg=0.0001, bnEps=2e-5, bnMom=0.9, reduce=False):\n",
    "    \n",
    "#     shortcut = data\n",
    "    \n",
    "#     bn1 = BatchNormalization(axis=chanDim, epsilon=bnEps,\n",
    "#             momentum=bnMom)(data)\n",
    "#     act1 = Activation(\"relu\")(bn1)\n",
    "    \n",
    "#     conv1 = Conv2D(int(K * 0.25), (1, 1), use_bias=False,\n",
    "#                 kernel_regularizer=l2(reg))(act1)\n",
    "    \n",
    "    \n",
    "#     bn2 = BatchNormalization(axis=chanDim, epsilon=bnEps,\n",
    "#                 momentum=bnMom)(conv1)\n",
    "#     act2 = Activation(\"relu\")(bn2)\n",
    "#     conv2 = Conv2D(int(K * 0.25), (3, 3), strides=stride,\n",
    "#                 padding=\"same\", use_bias=False,\n",
    "#     kernel_regularizer=l2(reg))(act2)\n",
    "    \n",
    "    \n",
    "#     bn3 = BatchNormalization(axis=chanDim, epsilon=bnEps,\n",
    "#                 momentum=bnMom)(conv2)\n",
    "#     act3 = Activation(\"relu\")(bn3)\n",
    "#     conv3 = Conv2D(K, (1, 1), use_bias=False,\n",
    "#                 kernel_regularizer=l2(reg))(act3)\n",
    "    \n",
    "    \n",
    "    \n",
    "#     if reduce:\n",
    "#         shortcut = Conv2D(K, (1, 1), strides=stride,\n",
    "#             use_bias=False, kernel_regularizer=l2(reg))(act1)\n",
    "    \n",
    "#     x = add([conv3, shortcut])\n",
    "    \n",
    "    \n",
    "    \n",
    "#     return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def build_Resnet(width, height, depth, classes, stages, filters,\n",
    "#                 reg=0.0001, bnEps=2e-5, bnMom=0.9):\n",
    "    \n",
    "    \n",
    "#     inputShape = (height, width, depth)\n",
    "#     chanDim = -1\n",
    "#     inputs = Input(shape=inputShape)\n",
    "#     x = BatchNormalization(axis=chanDim, epsilon=bnEps,\n",
    "#                             momentum=bnMom)(inputs)\n",
    "#     x = Conv2D(filters[0], (3, 3), use_bias=False,padding=\"same\", kernel_regularizer=l2(reg))(x)\n",
    "    \n",
    "    \n",
    "    \n",
    "#     for i in range(0, len(stages)):\n",
    "\n",
    "#         stride = (1, 1) if i == 0 else (2, 2)\n",
    "        \n",
    "#         x = residual_module(x, filters[i + 1], stride,\n",
    "#                 chanDim, reduce=True, bnEps=bnEps, bnMom=bnMom)\n",
    "        \n",
    "#         for j in range(0, stages[i] - 1):\n",
    "            \n",
    "#             x = residual_module(x, filters[i + 1],\n",
    "#                     (1, 1), chanDim, bnEps=bnEps, bnMom=bnMom)\n",
    "            \n",
    "#     x = BatchNormalization(axis=chanDim, epsilon=bnEps,\n",
    "#                             momentum=bnMom)(x)\n",
    "#     x = Activation(\"relu\")(x)\n",
    "#     x = AveragePooling2D((8, 8))(x) \n",
    "#     x = Flatten()(x)\n",
    "#     x = Dense(classes, kernel_regularizer=l2(reg))(x)\n",
    "#     x = Activation(\"softmax\", dtype='float32')(x)\n",
    "    \n",
    "#     model = Model(inputs, x, name=\"resnet\")\n",
    "    \n",
    "    \n",
    "    \n",
    "#     return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    \n",
    "    \n",
    "    \n",
    "    from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "    from tensorflow.keras import datasets, layers, models\n",
    "    from tensorflow.keras.callbacks import EarlyStopping\n",
    "    from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "    from tensorflow.keras.models import Sequential, Model\n",
    "    from tensorflow.keras.layers import BatchNormalization, Conv2D, MaxPooling2D, Flatten, Dense, AveragePooling2D\n",
    "    from tensorflow.keras.layers import ZeroPadding2D, add, Input, Activation\n",
    "    from tensorflow.keras.regularizers import l2\n",
    "    from sklearn.preprocessing import LabelBinarizer\n",
    "    from tensorflow.keras.optimizers import SGD\n",
    "    from tensorflow.keras.optimizers import Adam\n",
    "    from tensorflow.keras.datasets import cifar10\n",
    "    from tensorflow.keras import backend as K\n",
    "    import tensorflow as tf\n",
    "    from tensorflow import keras\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    policy = mixed_precision.Policy('mixed_float16')\n",
    "    mixed_precision.set_policy(policy)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def residual_module(data, K, stride, chanDim,\n",
    "                    reg=0.0001, bnEps=2e-5, bnMom=0.9, reduce=False):\n",
    "    \n",
    "        shortcut = data\n",
    "\n",
    "        bn1 = BatchNormalization(axis=chanDim, epsilon=bnEps,\n",
    "                momentum=bnMom)(data)\n",
    "        act1 = Activation(\"elu\")(bn1)\n",
    "\n",
    "        conv1 = Conv2D(int(K * 0.25), (1, 1), use_bias=False,\n",
    "                    kernel_regularizer=l2(reg))(act1)\n",
    "\n",
    "\n",
    "        bn2 = BatchNormalization(axis=chanDim, epsilon=bnEps,\n",
    "                    momentum=bnMom)(conv1)\n",
    "        act2 = Activation(\"elu\")(bn2)\n",
    "        conv2 = Conv2D(int(K * 0.25), (3, 3), strides=stride,\n",
    "                    padding=\"same\", use_bias=False,\n",
    "        kernel_regularizer=l2(reg))(act2)\n",
    "\n",
    "\n",
    "        bn3 = BatchNormalization(axis=chanDim, epsilon=bnEps,\n",
    "                    momentum=bnMom)(conv2)\n",
    "        act3 = Activation(\"elu\")(bn3)\n",
    "        conv3 = Conv2D(K, (1, 1), use_bias=False,\n",
    "                    kernel_regularizer=l2(reg))(act3)\n",
    "\n",
    "\n",
    "\n",
    "        if reduce:\n",
    "            shortcut = Conv2D(K, (1, 1), strides=stride,\n",
    "                use_bias=False, kernel_regularizer=l2(reg))(act1)\n",
    "\n",
    "        x = add([conv3, shortcut])\n",
    "    \n",
    "    \n",
    "    \n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def build_Resnet(width, height, depth, classes, stages, filters,\n",
    "                    reg=0.0001, bnEps=2e-5, bnMom=0.9):\n",
    "\n",
    "\n",
    "        inputShape = (height, width, depth)\n",
    "        chanDim = -1\n",
    "        inputs = Input(shape=inputShape)\n",
    "        x = BatchNormalization(axis=chanDim, epsilon=bnEps,\n",
    "                                momentum=bnMom)(inputs)\n",
    "        x = Conv2D(filters[0], (3, 3), use_bias=False,padding=\"same\", kernel_regularizer=l2(reg))(x)\n",
    "\n",
    "\n",
    "\n",
    "        for i in range(0, len(stages)):\n",
    "\n",
    "            stride = (1, 1) if i == 0 else (2, 2)\n",
    "\n",
    "            x = residual_module(x, filters[i + 1], stride,\n",
    "                    chanDim, reduce=True, bnEps=bnEps, bnMom=bnMom)\n",
    "\n",
    "            for j in range(0, stages[i] - 1):\n",
    "\n",
    "                x = residual_module(x, filters[i + 1],\n",
    "                        (1, 1), chanDim, bnEps=bnEps, bnMom=bnMom)\n",
    "\n",
    "        x = BatchNormalization(axis=chanDim, epsilon=bnEps,\n",
    "                                momentum=bnMom)(x)\n",
    "        x = Activation(\"elu\")(x)\n",
    "        x = AveragePooling2D((8, 8))(x) \n",
    "        x = Flatten()(x)\n",
    "        x = Dense(classes, kernel_regularizer=l2(reg))(x)\n",
    "        x = Activation(\"softmax\", dtype='float32')(x)\n",
    "\n",
    "        model = Model(inputs, x, name=\"resnet\")\n",
    "\n",
    "\n",
    "\n",
    "        return model\n",
    "\n",
    "    \n",
    "    wandb.init()\n",
    "    configs = {'learning_rate': 2e-2,'reg': 0.0009,'decay':0.001 }\n",
    "    config = wandb.config\n",
    "    config.epochs = 100\n",
    "    \n",
    "    \n",
    "    \n",
    "    model = build_Resnet(32, 32, 3, 10, (9, 9, 9),\n",
    "                                (64, 64, 128, 256), reg=wandb.config.reg)\n",
    "    \n",
    "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=30)\n",
    "\n",
    "    metric = \"val_accuracy\"\n",
    "\n",
    "    checkpoint = ModelCheckpoint(\"ResNet_Cifar10.h5\", monitor= metric, verbose=1, save_best_only=True,\n",
    "                             save_weights_only=False, mode='auto')\n",
    "    \n",
    "    \n",
    "    #n_epochs = 100\n",
    "    batch = 128\n",
    "#     s = 100 * len(trainX) // batch # number of steps in 20 epochs (batch size = 32)\n",
    "#     learning_rate0 = keras.optimizers.schedules.ExponentialDecay(wandb.config.learning_rate, s\n",
    "#                                                                  , wandb.config.decay)\n",
    "\n",
    "    opt = Adam(wandb.config.learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-07\n",
    "               , decay=wandb.config.decay, amsgrad=True)\n",
    "    #opt = opt = SGD(lr= wandb.config.learning_rate ,decay = wandb.config.decay ,  momentum= 0.9, nesterov=True)\n",
    "    \n",
    "    \n",
    "    model.compile(optimizer=opt,\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    wandb_callback = WandbCallback(data_type= \"image\", validation_data=(testX, testY)\n",
    "                                 , labels = labelNames)\n",
    "\n",
    "    history = model.fit_generator(aug.flow(trainX, trainY, batch_size=batch), epochs=config.epochs, \n",
    "                    validation_data=(testX, testY),steps_per_epoch=len(trainX) // batch,\n",
    "                    callbacks=[es,checkpoint,wandb_callback], verbose=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: 1ohu91e8 with config:\n",
      "\tdecay: 0.004\n",
      "\tlearning_rate: 0.02\n",
      "\treg: 0.05\n",
      "wandb: Agent Started Run: 1ohu91e8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/roastedkernel/ResNet_Cifar10_HyperParam_Adam\" target=\"_blank\">https://app.wandb.ai/roastedkernel/ResNet_Cifar10_HyperParam_Adam</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/roastedkernel/ResNet_Cifar10_HyperParam_Adam/sweeps/vv5ax67l\" target=\"_blank\">https://app.wandb.ai/roastedkernel/ResNet_Cifar10_HyperParam_Adam/sweeps/vv5ax67l</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/roastedkernel/ResNet_Cifar10_HyperParam_Adam/runs/1ohu91e8\" target=\"_blank\">https://app.wandb.ai/roastedkernel/ResNet_Cifar10_HyperParam_Adam/runs/1ohu91e8</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Wandb version 0.10.0 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-8-7d67ea591195>:149: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.30990, saving model to ResNet_Cifar10.h5\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.30990 to 0.44130, saving model to ResNet_Cifar10.h5\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.44130 to 0.50050, saving model to ResNet_Cifar10.h5\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.50050 to 0.55750, saving model to ResNet_Cifar10.h5\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Network error resolved after 0:00:54.491182, resuming normal operation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00005: val_accuracy improved from 0.55750 to 0.59310, saving model to ResNet_Cifar10.h5\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.59310 to 0.59620, saving model to ResNet_Cifar10.h5\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.59620 to 0.66160, saving model to ResNet_Cifar10.h5\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.66160\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.66160 to 0.71140, saving model to ResNet_Cifar10.h5\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.71140 to 0.76120, saving model to ResNet_Cifar10.h5\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Network error resolved after 0:00:26.880200, resuming normal operation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.76120\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.76120 to 0.77780, saving model to ResNet_Cifar10.h5\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.77780\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.77780 to 0.78540, saving model to ResNet_Cifar10.h5\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.78540 to 0.80160, saving model to ResNet_Cifar10.h5\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.80160\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.80160 to 0.82520, saving model to ResNet_Cifar10.h5\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.82520\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.82520\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: val_accuracy improved from 0.82520 to 0.84100, saving model to ResNet_Cifar10.h5\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: val_accuracy improved from 0.84100 to 0.84150, saving model to ResNet_Cifar10.h5\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.84150\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: val_accuracy improved from 0.84150 to 0.85830, saving model to ResNet_Cifar10.h5\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.85830\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.85830\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 00026: val_accuracy improved from 0.85830 to 0.85900, saving model to ResNet_Cifar10.h5\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 00027: val_accuracy improved from 0.85900 to 0.86130, saving model to ResNet_Cifar10.h5\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Network error resolved after 0:00:42.436506, resuming normal operation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.86130\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 00029: val_accuracy improved from 0.86130 to 0.87190, saving model to ResNet_Cifar10.h5\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 00030: val_accuracy improved from 0.87190 to 0.87640, saving model to ResNet_Cifar10.h5\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.87640\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 00032: val_accuracy improved from 0.87640 to 0.87810, saving model to ResNet_Cifar10.h5\n",
      "Epoch 33/100\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.87810\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.87810\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.87810\n",
      "Epoch 36/100\n",
      "\n",
      "Epoch 00036: val_accuracy improved from 0.87810 to 0.88330, saving model to ResNet_Cifar10.h5\n",
      "Epoch 37/100\n",
      "\n",
      "Epoch 00037: val_accuracy improved from 0.88330 to 0.88520, saving model to ResNet_Cifar10.h5\n",
      "Epoch 38/100\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.88520\n",
      "Epoch 39/100\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.88520\n",
      "Epoch 40/100\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.88520\n",
      "Epoch 41/100\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.88520\n",
      "Epoch 42/100\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.88520\n",
      "Epoch 43/100\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.88520\n",
      "Epoch 44/100\n",
      "\n",
      "Epoch 00044: val_accuracy improved from 0.88520 to 0.88820, saving model to ResNet_Cifar10.h5\n",
      "Epoch 45/100\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.88820\n",
      "Epoch 46/100\n",
      "\n",
      "Epoch 00046: val_accuracy improved from 0.88820 to 0.89470, saving model to ResNet_Cifar10.h5\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Network error resolved after 0:00:30.373560, resuming normal operation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00047: val_accuracy improved from 0.89470 to 0.89520, saving model to ResNet_Cifar10.h5\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Error uploading \"media/images/examples_45.png\": CommError, File /tmp/tmp5qr3hn1dwandb/2zhddfup-media/images/examples_45.png size shrank from 77571 to 36611 while it was being uploaded.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Network error resolved after 0:00:26.166494, resuming normal operation.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Network error resolved after 0:00:31.009247, resuming normal operation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.89520\n",
      "Epoch 49/100\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.89520\n",
      "Epoch 50/100\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.89520\n",
      "Epoch 51/100\n",
      "\n",
      "Epoch 00051: val_accuracy improved from 0.89520 to 0.89850, saving model to ResNet_Cifar10.h5\n",
      "Epoch 52/100\n",
      "\n",
      "Epoch 00052: val_accuracy did not improve from 0.89850\n",
      "Epoch 53/100\n",
      "\n",
      "Epoch 00053: val_accuracy improved from 0.89850 to 0.90010, saving model to ResNet_Cifar10.h5\n",
      "Epoch 54/100\n",
      "\n",
      "Epoch 00054: val_accuracy did not improve from 0.90010\n",
      "Epoch 55/100\n",
      "\n",
      "Epoch 00055: val_accuracy did not improve from 0.90010\n",
      "Epoch 56/100\n",
      "\n",
      "Epoch 00056: val_accuracy did not improve from 0.90010\n",
      "Epoch 57/100\n",
      "\n",
      "Epoch 00057: val_accuracy did not improve from 0.90010\n",
      "Epoch 58/100\n",
      "\n",
      "Epoch 00058: val_accuracy did not improve from 0.90010\n",
      "Epoch 59/100\n",
      "\n",
      "Epoch 00059: val_accuracy did not improve from 0.90010\n",
      "Epoch 60/100\n",
      "\n",
      "Epoch 00060: val_accuracy improved from 0.90010 to 0.90080, saving model to ResNet_Cifar10.h5\n",
      "Epoch 61/100\n",
      "\n",
      "Epoch 00061: val_accuracy improved from 0.90080 to 0.90370, saving model to ResNet_Cifar10.h5\n",
      "Epoch 62/100\n",
      "\n",
      "Epoch 00062: val_accuracy did not improve from 0.90370\n",
      "Epoch 63/100\n",
      "\n",
      "Epoch 00063: val_accuracy did not improve from 0.90370\n",
      "Epoch 64/100\n",
      "\n",
      "Epoch 00064: val_accuracy did not improve from 0.90370\n",
      "Epoch 65/100\n",
      "\n",
      "Epoch 00065: val_accuracy improved from 0.90370 to 0.90620, saving model to ResNet_Cifar10.h5\n",
      "Epoch 66/100\n",
      "\n",
      "Epoch 00066: val_accuracy did not improve from 0.90620\n",
      "Epoch 67/100\n",
      "\n",
      "Epoch 00067: val_accuracy did not improve from 0.90620\n",
      "Epoch 68/100\n",
      "\n",
      "Epoch 00068: val_accuracy did not improve from 0.90620\n",
      "Epoch 69/100\n",
      "\n",
      "Epoch 00069: val_accuracy did not improve from 0.90620\n",
      "Epoch 70/100\n",
      "\n",
      "Epoch 00070: val_accuracy did not improve from 0.90620\n",
      "Epoch 71/100\n",
      "\n",
      "Epoch 00071: val_accuracy did not improve from 0.90620\n",
      "Epoch 72/100\n",
      "\n",
      "Epoch 00072: val_accuracy did not improve from 0.90620\n",
      "Epoch 73/100\n",
      "\n",
      "Epoch 00073: val_accuracy did not improve from 0.90620\n",
      "Epoch 74/100\n",
      "\n",
      "Epoch 00074: val_accuracy did not improve from 0.90620\n",
      "Epoch 75/100\n",
      "\n",
      "Epoch 00075: val_accuracy did not improve from 0.90620\n",
      "Epoch 76/100\n",
      "\n",
      "Epoch 00076: val_accuracy did not improve from 0.90620\n",
      "Epoch 77/100\n",
      "\n",
      "Epoch 00077: val_accuracy did not improve from 0.90620\n",
      "Epoch 78/100\n",
      "\n",
      "Epoch 00078: val_accuracy did not improve from 0.90620\n",
      "Epoch 79/100\n",
      "\n",
      "Epoch 00079: val_accuracy did not improve from 0.90620\n",
      "Epoch 80/100\n",
      "\n",
      "Epoch 00080: val_accuracy improved from 0.90620 to 0.90850, saving model to ResNet_Cifar10.h5\n",
      "Epoch 81/100\n",
      "\n",
      "Epoch 00081: val_accuracy did not improve from 0.90850\n",
      "Epoch 82/100\n",
      "\n",
      "Epoch 00082: val_accuracy improved from 0.90850 to 0.90940, saving model to ResNet_Cifar10.h5\n",
      "Epoch 83/100\n",
      "\n",
      "Epoch 00083: val_accuracy did not improve from 0.90940\n",
      "Epoch 84/100\n",
      "\n",
      "Epoch 00084: val_accuracy did not improve from 0.90940\n",
      "Epoch 85/100\n",
      "\n",
      "Epoch 00085: val_accuracy did not improve from 0.90940\n",
      "Epoch 86/100\n",
      "\n",
      "Epoch 00086: val_accuracy did not improve from 0.90940\n",
      "Epoch 87/100\n",
      "\n",
      "Epoch 00087: val_accuracy did not improve from 0.90940\n",
      "Epoch 88/100\n",
      "\n",
      "Epoch 00088: val_accuracy did not improve from 0.90940\n",
      "Epoch 89/100\n",
      "\n",
      "Epoch 00089: val_accuracy did not improve from 0.90940\n",
      "Epoch 90/100\n",
      "\n",
      "Epoch 00090: val_accuracy did not improve from 0.90940\n",
      "Epoch 91/100\n",
      "\n",
      "Epoch 00091: val_accuracy did not improve from 0.90940\n",
      "Epoch 92/100\n",
      "\n",
      "Epoch 00092: val_accuracy did not improve from 0.90940\n",
      "Epoch 93/100\n",
      "\n",
      "Epoch 00093: val_accuracy did not improve from 0.90940\n",
      "Epoch 94/100\n",
      "\n",
      "Epoch 00094: val_accuracy improved from 0.90940 to 0.91020, saving model to ResNet_Cifar10.h5\n",
      "Epoch 95/100\n",
      "\n",
      "Epoch 00095: val_accuracy did not improve from 0.91020\n",
      "Epoch 96/100\n",
      "\n",
      "Epoch 00096: val_accuracy did not improve from 0.91020\n",
      "Epoch 97/100\n",
      "\n",
      "Epoch 00097: val_accuracy did not improve from 0.91020\n",
      "Epoch 98/100\n",
      "\n",
      "Epoch 00098: val_accuracy did not improve from 0.91020\n",
      "Epoch 99/100\n",
      "\n",
      "Epoch 00099: val_accuracy improved from 0.91020 to 0.91110, saving model to ResNet_Cifar10.h5\n",
      "Epoch 100/100\n",
      "\n",
      "Epoch 00100: val_accuracy did not improve from 0.91110\n",
      "wandb: Agent Finished Run: 1ohu91e8 \n",
      "\n",
      "wandb: Agent Starting Run: vq5h4ru5 with config:\n",
      "\tdecay: 0.004\n",
      "\tlearning_rate: 0.02\n",
      "\treg: 0.04\n",
      "wandb: Agent Started Run: vq5h4ru5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/roastedkernel/ResNet_Cifar10_HyperParam_Adam\" target=\"_blank\">https://app.wandb.ai/roastedkernel/ResNet_Cifar10_HyperParam_Adam</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/roastedkernel/ResNet_Cifar10_HyperParam_Adam/sweeps/vv5ax67l\" target=\"_blank\">https://app.wandb.ai/roastedkernel/ResNet_Cifar10_HyperParam_Adam/sweeps/vv5ax67l</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/roastedkernel/ResNet_Cifar10_HyperParam_Adam/runs/vq5h4ru5\" target=\"_blank\">https://app.wandb.ai/roastedkernel/ResNet_Cifar10_HyperParam_Adam/runs/vq5h4ru5</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Wandb version 0.10.0 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-8-7d67ea591195>:149: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.32550, saving model to ResNet_Cifar10.h5\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.32550 to 0.42180, saving model to ResNet_Cifar10.h5\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.42180 to 0.51250, saving model to ResNet_Cifar10.h5\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.51250 to 0.54880, saving model to ResNet_Cifar10.h5\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.54880\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.54880 to 0.63280, saving model to ResNet_Cifar10.h5\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.63280\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.63280\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.63280 to 0.69450, saving model to ResNet_Cifar10.h5\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.69450 to 0.70260, saving model to ResNet_Cifar10.h5\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.70260 to 0.72550, saving model to ResNet_Cifar10.h5\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.72550 to 0.76440, saving model to ResNet_Cifar10.h5\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.76440\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Network error resolved after 0:00:20.370298, resuming normal operation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.76440\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.76440 to 0.77810, saving model to ResNet_Cifar10.h5\n",
      "Epoch 16/100\n"
     ]
    }
   ],
   "source": [
    "wandb.agent(sweep_id, function=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
