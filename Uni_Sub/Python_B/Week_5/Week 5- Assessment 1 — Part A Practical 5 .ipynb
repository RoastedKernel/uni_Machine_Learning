{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "import tarfile\n",
    "import urllib\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "# from sklearn dataset to panda dataframe\n",
    "def sklearn_to_df(sklearn_dataset):\n",
    "    df = pd.DataFrame(sklearn_dataset.data, columns=sklearn_dataset.feature_names)\n",
    "    df['target'] = pd.Series(sklearn_dataset.target)\n",
    "    return df\n",
    "\n",
    "data_sk = load_diabetes()\n",
    "\n",
    "data = sklearn_to_df(data_sk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[ 0.03807591,  0.05068012,  0.06169621, ..., -0.00259226,\n",
       "          0.01990842, -0.01764613],\n",
       "        [-0.00188202, -0.04464164, -0.05147406, ..., -0.03949338,\n",
       "         -0.06832974, -0.09220405],\n",
       "        [ 0.08529891,  0.05068012,  0.04445121, ..., -0.00259226,\n",
       "          0.00286377, -0.02593034],\n",
       "        ...,\n",
       "        [ 0.04170844,  0.05068012, -0.01590626, ..., -0.01107952,\n",
       "         -0.04687948,  0.01549073],\n",
       "        [-0.04547248, -0.04464164,  0.03906215, ...,  0.02655962,\n",
       "          0.04452837, -0.02593034],\n",
       "        [-0.04547248, -0.04464164, -0.0730303 , ..., -0.03949338,\n",
       "         -0.00421986,  0.00306441]]),\n",
       " 'target': array([151.,  75., 141., 206., 135.,  97., 138.,  63., 110., 310., 101.,\n",
       "         69., 179., 185., 118., 171., 166., 144.,  97., 168.,  68.,  49.,\n",
       "         68., 245., 184., 202., 137.,  85., 131., 283., 129.,  59., 341.,\n",
       "         87.,  65., 102., 265., 276., 252.,  90., 100.,  55.,  61.,  92.,\n",
       "        259.,  53., 190., 142.,  75., 142., 155., 225.,  59., 104., 182.,\n",
       "        128.,  52.,  37., 170., 170.,  61., 144.,  52., 128.,  71., 163.,\n",
       "        150.,  97., 160., 178.,  48., 270., 202., 111.,  85.,  42., 170.,\n",
       "        200., 252., 113., 143.,  51.,  52., 210.,  65., 141.,  55., 134.,\n",
       "         42., 111.,  98., 164.,  48.,  96.,  90., 162., 150., 279.,  92.,\n",
       "         83., 128., 102., 302., 198.,  95.,  53., 134., 144., 232.,  81.,\n",
       "        104.,  59., 246., 297., 258., 229., 275., 281., 179., 200., 200.,\n",
       "        173., 180.,  84., 121., 161.,  99., 109., 115., 268., 274., 158.,\n",
       "        107.,  83., 103., 272.,  85., 280., 336., 281., 118., 317., 235.,\n",
       "         60., 174., 259., 178., 128.,  96., 126., 288.,  88., 292.,  71.,\n",
       "        197., 186.,  25.,  84.,  96., 195.,  53., 217., 172., 131., 214.,\n",
       "         59.,  70., 220., 268., 152.,  47.,  74., 295., 101., 151., 127.,\n",
       "        237., 225.,  81., 151., 107.,  64., 138., 185., 265., 101., 137.,\n",
       "        143., 141.,  79., 292., 178.,  91., 116.,  86., 122.,  72., 129.,\n",
       "        142.,  90., 158.,  39., 196., 222., 277.,  99., 196., 202., 155.,\n",
       "         77., 191.,  70.,  73.,  49.,  65., 263., 248., 296., 214., 185.,\n",
       "         78.,  93., 252., 150.,  77., 208.,  77., 108., 160.,  53., 220.,\n",
       "        154., 259.,  90., 246., 124.,  67.,  72., 257., 262., 275., 177.,\n",
       "         71.,  47., 187., 125.,  78.,  51., 258., 215., 303., 243.,  91.,\n",
       "        150., 310., 153., 346.,  63.,  89.,  50.,  39., 103., 308., 116.,\n",
       "        145.,  74.,  45., 115., 264.,  87., 202., 127., 182., 241.,  66.,\n",
       "         94., 283.,  64., 102., 200., 265.,  94., 230., 181., 156., 233.,\n",
       "         60., 219.,  80.,  68., 332., 248.,  84., 200.,  55.,  85.,  89.,\n",
       "         31., 129.,  83., 275.,  65., 198., 236., 253., 124.,  44., 172.,\n",
       "        114., 142., 109., 180., 144., 163., 147.,  97., 220., 190., 109.,\n",
       "        191., 122., 230., 242., 248., 249., 192., 131., 237.,  78., 135.,\n",
       "        244., 199., 270., 164.,  72.,  96., 306.,  91., 214.,  95., 216.,\n",
       "        263., 178., 113., 200., 139., 139.,  88., 148.,  88., 243.,  71.,\n",
       "         77., 109., 272.,  60.,  54., 221.,  90., 311., 281., 182., 321.,\n",
       "         58., 262., 206., 233., 242., 123., 167.,  63., 197.,  71., 168.,\n",
       "        140., 217., 121., 235., 245.,  40.,  52., 104., 132.,  88.,  69.,\n",
       "        219.,  72., 201., 110.,  51., 277.,  63., 118.,  69., 273., 258.,\n",
       "         43., 198., 242., 232., 175.,  93., 168., 275., 293., 281.,  72.,\n",
       "        140., 189., 181., 209., 136., 261., 113., 131., 174., 257.,  55.,\n",
       "         84.,  42., 146., 212., 233.,  91., 111., 152., 120.,  67., 310.,\n",
       "         94., 183.,  66., 173.,  72.,  49.,  64.,  48., 178., 104., 132.,\n",
       "        220.,  57.]),\n",
       " 'DESCR': '.. _diabetes_dataset:\\n\\nDiabetes dataset\\n----------------\\n\\nTen baseline variables, age, sex, body mass index, average blood\\npressure, and six blood serum measurements were obtained for each of n =\\n442 diabetes patients, as well as the response of interest, a\\nquantitative measure of disease progression one year after baseline.\\n\\n**Data Set Characteristics:**\\n\\n  :Number of Instances: 442\\n\\n  :Number of Attributes: First 10 columns are numeric predictive values\\n\\n  :Target: Column 11 is a quantitative measure of disease progression one year after baseline\\n\\n  :Attribute Information:\\n      - Age\\n      - Sex\\n      - Body mass index\\n      - Average blood pressure\\n      - S1\\n      - S2\\n      - S3\\n      - S4\\n      - S5\\n      - S6\\n\\nNote: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times `n_samples` (i.e. the sum of squares of each column totals 1).\\n\\nSource URL:\\nhttps://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\\n\\nFor more information see:\\nBradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\\n(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)',\n",
       " 'feature_names': ['age',\n",
       "  'sex',\n",
       "  'bmi',\n",
       "  'bp',\n",
       "  's1',\n",
       "  's2',\n",
       "  's3',\n",
       "  's4',\n",
       "  's5',\n",
       "  's6'],\n",
       " 'data_filename': '/home/roasted_kernel/anaconda3/lib/python3.7/site-packages/sklearn/datasets/data/diabetes_data.csv.gz',\n",
       " 'target_filename': '/home/roasted_kernel/anaconda3/lib/python3.7/site-packages/sklearn/datasets/data/diabetes_target.csv.gz'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _diabetes_dataset:\n",
      "\n",
      "Diabetes dataset\n",
      "----------------\n",
      "\n",
      "Ten baseline variables, age, sex, body mass index, average blood\n",
      "pressure, and six blood serum measurements were obtained for each of n =\n",
      "442 diabetes patients, as well as the response of interest, a\n",
      "quantitative measure of disease progression one year after baseline.\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "  :Number of Instances: 442\n",
      "\n",
      "  :Number of Attributes: First 10 columns are numeric predictive values\n",
      "\n",
      "  :Target: Column 11 is a quantitative measure of disease progression one year after baseline\n",
      "\n",
      "  :Attribute Information:\n",
      "      - Age\n",
      "      - Sex\n",
      "      - Body mass index\n",
      "      - Average blood pressure\n",
      "      - S1\n",
      "      - S2\n",
      "      - S3\n",
      "      - S4\n",
      "      - S5\n",
      "      - S6\n",
      "\n",
      "Note: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times `n_samples` (i.e. the sum of squares of each column totals 1).\n",
      "\n",
      "Source URL:\n",
      "https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\n",
      "\n",
      "For more information see:\n",
      "Bradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\n",
      "(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)\n"
     ]
    }
   ],
   "source": [
    "#dataset information provided by sklearn.\n",
    "print(data_sk.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.061696</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>-0.044223</td>\n",
       "      <td>-0.034821</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.019908</td>\n",
       "      <td>-0.017646</td>\n",
       "      <td>151.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001882</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.051474</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>-0.019163</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.068330</td>\n",
       "      <td>-0.092204</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085299</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>-0.005671</td>\n",
       "      <td>-0.045599</td>\n",
       "      <td>-0.034194</td>\n",
       "      <td>-0.032356</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.002864</td>\n",
       "      <td>-0.025930</td>\n",
       "      <td>141.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089063</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.011595</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.024991</td>\n",
       "      <td>-0.036038</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.022692</td>\n",
       "      <td>-0.009362</td>\n",
       "      <td>206.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005383</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.036385</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.015596</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.031991</td>\n",
       "      <td>-0.046641</td>\n",
       "      <td>135.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>-0.056370</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.074108</td>\n",
       "      <td>-0.050428</td>\n",
       "      <td>-0.024960</td>\n",
       "      <td>-0.047034</td>\n",
       "      <td>0.092820</td>\n",
       "      <td>-0.076395</td>\n",
       "      <td>-0.061177</td>\n",
       "      <td>-0.046641</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>0.041708</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.019662</td>\n",
       "      <td>0.059744</td>\n",
       "      <td>-0.005697</td>\n",
       "      <td>-0.002566</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.031193</td>\n",
       "      <td>0.007207</td>\n",
       "      <td>178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>-0.005515</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.015906</td>\n",
       "      <td>-0.067642</td>\n",
       "      <td>0.049341</td>\n",
       "      <td>0.079165</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>-0.018118</td>\n",
       "      <td>0.044485</td>\n",
       "      <td>104.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>0.041708</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.015906</td>\n",
       "      <td>0.017282</td>\n",
       "      <td>-0.037344</td>\n",
       "      <td>-0.013840</td>\n",
       "      <td>-0.024993</td>\n",
       "      <td>-0.011080</td>\n",
       "      <td>-0.046879</td>\n",
       "      <td>0.015491</td>\n",
       "      <td>132.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>-0.045472</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.001215</td>\n",
       "      <td>0.016318</td>\n",
       "      <td>0.015283</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>0.026560</td>\n",
       "      <td>0.044528</td>\n",
       "      <td>-0.025930</td>\n",
       "      <td>220.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>441 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          age       sex       bmi        bp        s1        s2        s3  \\\n",
       "0    0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
       "1   -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
       "2    0.085299  0.050680  0.044451 -0.005671 -0.045599 -0.034194 -0.032356   \n",
       "3   -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
       "4    0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "436 -0.056370 -0.044642 -0.074108 -0.050428 -0.024960 -0.047034  0.092820   \n",
       "437  0.041708  0.050680  0.019662  0.059744 -0.005697 -0.002566 -0.028674   \n",
       "438 -0.005515  0.050680 -0.015906 -0.067642  0.049341  0.079165 -0.028674   \n",
       "439  0.041708  0.050680 -0.015906  0.017282 -0.037344 -0.013840 -0.024993   \n",
       "440 -0.045472 -0.044642  0.039062  0.001215  0.016318  0.015283 -0.028674   \n",
       "\n",
       "           s4        s5        s6  target  \n",
       "0   -0.002592  0.019908 -0.017646   151.0  \n",
       "1   -0.039493 -0.068330 -0.092204    75.0  \n",
       "2   -0.002592  0.002864 -0.025930   141.0  \n",
       "3    0.034309  0.022692 -0.009362   206.0  \n",
       "4   -0.002592 -0.031991 -0.046641   135.0  \n",
       "..        ...       ...       ...     ...  \n",
       "436 -0.076395 -0.061177 -0.046641    48.0  \n",
       "437 -0.002592  0.031193  0.007207   178.0  \n",
       "438  0.034309 -0.018118  0.044485   104.0  \n",
       "439 -0.011080 -0.046879  0.015491   132.0  \n",
       "440  0.026560  0.044528 -0.025930   220.0  \n",
       "\n",
       "[441 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the features set and target \n",
    "data.head(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 442 entries, 0 to 441\n",
      "Data columns (total 11 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   age     442 non-null    float64\n",
      " 1   sex     442 non-null    float64\n",
      " 2   bmi     442 non-null    float64\n",
      " 3   bp      442 non-null    float64\n",
      " 4   s1      442 non-null    float64\n",
      " 5   s2      442 non-null    float64\n",
      " 6   s3      442 non-null    float64\n",
      " 7   s4      442 non-null    float64\n",
      " 8   s5      442 non-null    float64\n",
      " 9   s6      442 non-null    float64\n",
      " 10  target  442 non-null    float64\n",
      "dtypes: float64(11)\n",
      "memory usage: 38.1 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f766095fbd0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#checking the distrbution of the target.\n",
    "sns.distplot(data[\"target\"], bins= 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target    1.000000\n",
       "bmi       0.586450\n",
       "s5        0.565883\n",
       "bp        0.441484\n",
       "s4        0.430453\n",
       "s6        0.382483\n",
       "s1        0.212022\n",
       "age       0.187889\n",
       "s2        0.174054\n",
       "sex       0.043062\n",
       "s3       -0.394789\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Features that correlates to our target. \n",
    "corr_matrix = data.corr()\n",
    "corr_matrix['target'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Segregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data.drop(columns=\"target\")\n",
    "y = data[\"target\"]\n",
    "# split the dataset to train and test sets. \n",
    "X_train, X_test, y_train, y_test = train_test_split(X ,y , test_size= 0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71.64007462993281"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline = np.mean(y)\n",
    "#Get an array with baseline with the size of the testing dataset \n",
    "y_baseline = np.repeat(baseline, len(y_test))\n",
    "# import the metric \n",
    "from sklearn.metrics import mean_squared_error\n",
    "#y_test are the true values of y \n",
    "naive_RSME = mean_squared_error(y_test, y_baseline)\n",
    "naive_RSME=np.sqrt(naive_RSME)\n",
    "naive_RSME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71.65740368288068"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.dummy import DummyRegressor\n",
    "# Create the dummy regessor.\n",
    "dummy_regr = DummyRegressor(strategy=\"mean\")\n",
    "dummy_regr.fit(X_train, y_train)\n",
    "DummyRegressor()\n",
    "# baseline error for the dummy regressor.\n",
    "regression_RSME = mean_squared_error(y_test, dummy_regr.predict(X_test))\n",
    "regression_baseline = np.sqrt(regression_RSME)\n",
    "regression_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fucntion to print the results of the selected model against dummy regressor and naive \n",
    "def results(clf, X_train, X_test, y_train, y_test):\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    train_predict = clf.predict(X_train)\n",
    "    test_predict = clf.predict(X_test)\n",
    "    RMSE_training = np.sqrt(mean_squared_error(y_train, train_predict))\n",
    "    RMSE_test=np.sqrt(mean_squared_error(y_test, test_predict))\n",
    "    print('The naive RMSE baseline is ', naive_RSME)\n",
    "    print('The regression_baseline is ', regression_baseline)\n",
    "    print('The model performance in training is ', RMSE_training)\n",
    "    print('The model performance in testing is ', RMSE_test)\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1 Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "# \n",
    "svm_reg_rbf = SVR(kernel='rbf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1 results before hyperparameters tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The naive RMSE baseline is  71.64007462993281\n",
      "The regression_baseline is  71.65740368288068\n",
      "The model performance in training is  70.60131652005208\n",
      "The model performance in testing is  66.86508404451277\n"
     ]
    }
   ],
   "source": [
    "svm_reg_rbf.fit(X_train, y_train)\n",
    "\n",
    "results(svm_reg_rbf, X_train, X_test, y_train, y_test )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1 Training and Hyperparameter Tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 45000 candidates, totalling 225000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1832s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  48 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  62 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0470s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0792s.) Setting batch_size=8.\n",
      "[Parallel(n_jobs=-1)]: Done 128 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 188 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0488s.) Setting batch_size=16.\n",
      "[Parallel(n_jobs=-1)]: Done 308 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1431s.) Setting batch_size=32.\n",
      "[Parallel(n_jobs=-1)]: Done 492 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done 812 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1420 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done 2092 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done 2764 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done 3500 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done 4236 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done 5036 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=-1)]: Done 5836 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=-1)]: Done 6700 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=-1)]: Done 7564 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=-1)]: Done 8492 tasks      | elapsed:    6.9s\n",
      "[Parallel(n_jobs=-1)]: Done 9420 tasks      | elapsed:    7.5s\n",
      "[Parallel(n_jobs=-1)]: Done 10412 tasks      | elapsed:    8.1s\n",
      "[Parallel(n_jobs=-1)]: Done 11404 tasks      | elapsed:    8.8s\n",
      "[Parallel(n_jobs=-1)]: Done 12460 tasks      | elapsed:    9.5s\n",
      "[Parallel(n_jobs=-1)]: Done 13516 tasks      | elapsed:   10.3s\n",
      "[Parallel(n_jobs=-1)]: Done 14636 tasks      | elapsed:   11.0s\n",
      "[Parallel(n_jobs=-1)]: Done 15756 tasks      | elapsed:   11.7s\n",
      "[Parallel(n_jobs=-1)]: Done 16940 tasks      | elapsed:   12.5s\n",
      "[Parallel(n_jobs=-1)]: Done 18124 tasks      | elapsed:   13.4s\n",
      "[Parallel(n_jobs=-1)]: Done 19372 tasks      | elapsed:   14.1s\n",
      "[Parallel(n_jobs=-1)]: Done 20620 tasks      | elapsed:   14.9s\n",
      "[Parallel(n_jobs=-1)]: Done 21932 tasks      | elapsed:   15.8s\n",
      "[Parallel(n_jobs=-1)]: Done 23244 tasks      | elapsed:   16.7s\n",
      "[Parallel(n_jobs=-1)]: Done 24620 tasks      | elapsed:   17.5s\n",
      "[Parallel(n_jobs=-1)]: Done 25996 tasks      | elapsed:   18.4s\n",
      "[Parallel(n_jobs=-1)]: Done 27436 tasks      | elapsed:   19.5s\n",
      "[Parallel(n_jobs=-1)]: Done 28876 tasks      | elapsed:   20.5s\n",
      "[Parallel(n_jobs=-1)]: Done 30380 tasks      | elapsed:   21.4s\n",
      "[Parallel(n_jobs=-1)]: Done 31884 tasks      | elapsed:   22.4s\n",
      "[Parallel(n_jobs=-1)]: Done 33452 tasks      | elapsed:   24.2s\n",
      "[Parallel(n_jobs=-1)]: Done 35020 tasks      | elapsed:   26.1s\n",
      "[Parallel(n_jobs=-1)]: Done 36652 tasks      | elapsed:   27.5s\n",
      "[Parallel(n_jobs=-1)]: Done 38284 tasks      | elapsed:   28.6s\n",
      "[Parallel(n_jobs=-1)]: Done 39980 tasks      | elapsed:   29.8s\n",
      "[Parallel(n_jobs=-1)]: Done 41676 tasks      | elapsed:   31.0s\n",
      "[Parallel(n_jobs=-1)]: Done 43436 tasks      | elapsed:   32.2s\n",
      "[Parallel(n_jobs=-1)]: Done 45196 tasks      | elapsed:   33.4s\n",
      "[Parallel(n_jobs=-1)]: Done 47020 tasks      | elapsed:   34.7s\n",
      "[Parallel(n_jobs=-1)]: Done 48844 tasks      | elapsed:   36.0s\n",
      "[Parallel(n_jobs=-1)]: Done 50732 tasks      | elapsed:   37.2s\n",
      "[Parallel(n_jobs=-1)]: Done 52620 tasks      | elapsed:   38.5s\n",
      "[Parallel(n_jobs=-1)]: Done 54572 tasks      | elapsed:   40.0s\n",
      "[Parallel(n_jobs=-1)]: Done 56524 tasks      | elapsed:   41.5s\n",
      "[Parallel(n_jobs=-1)]: Done 58540 tasks      | elapsed:   42.9s\n",
      "[Parallel(n_jobs=-1)]: Done 60556 tasks      | elapsed:   44.2s\n",
      "[Parallel(n_jobs=-1)]: Done 62636 tasks      | elapsed:   45.6s\n",
      "[Parallel(n_jobs=-1)]: Done 64716 tasks      | elapsed:   47.1s\n",
      "[Parallel(n_jobs=-1)]: Done 66860 tasks      | elapsed:   48.6s\n",
      "[Parallel(n_jobs=-1)]: Done 69004 tasks      | elapsed:   50.1s\n",
      "[Parallel(n_jobs=-1)]: Done 71212 tasks      | elapsed:   51.7s\n",
      "[Parallel(n_jobs=-1)]: Done 73420 tasks      | elapsed:   53.3s\n",
      "[Parallel(n_jobs=-1)]: Done 75692 tasks      | elapsed:   54.7s\n",
      "[Parallel(n_jobs=-1)]: Done 77964 tasks      | elapsed:   56.3s\n",
      "[Parallel(n_jobs=-1)]: Done 80300 tasks      | elapsed:   57.9s\n",
      "[Parallel(n_jobs=-1)]: Done 82636 tasks      | elapsed:   59.6s\n",
      "[Parallel(n_jobs=-1)]: Done 85036 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 87436 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 89900 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 92364 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 94892 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 97420 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 100012 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 102604 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 105260 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 107916 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 110636 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 113356 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 116140 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 118924 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 121772 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 124620 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 127532 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 130444 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 133420 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 136396 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 139436 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 142476 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 145580 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 148684 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 151852 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 155020 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 158252 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 161484 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 164780 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 168076 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 171436 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 174796 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 178220 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 181644 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 185132 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 188620 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 192172 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 195724 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 199340 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 202956 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 206636 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 210316 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 214060 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 217804 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 221612 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 224610 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 224942 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 225000 out of 225000 | elapsed:  2.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 2807.2162039411755, 'epsilon': 0.1, 'gamma': 0.1}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# usage of gridsearch for hyperparameter selection\n",
    "\n",
    "#######################################\n",
    "# hyperparameter ranges \n",
    "C_range = np.logspace(2, 4 , 30)\n",
    "gamma_range = np.logspace(-4, -1, 30)\n",
    "epsilon_range = np.linspace(0.1,0.9)\n",
    "#######################################\n",
    "\n",
    "param_grid = dict(gamma=gamma_range, C=C_range, epsilon=epsilon_range)\n",
    "\n",
    "# initialize gridsearch\n",
    "grid_search_rbf = GridSearchCV(svm_reg_rbf, param_grid, n_jobs=-1, verbose=10,\n",
    "                                        cv=5, scoring=\"neg_root_mean_squared_error\")\n",
    "    \n",
    "# fit and find the best parameters.    \n",
    "grid_search_rbf.fit(X_train,y_train)\n",
    "grid_search_rbf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   100.        ,    126.89610032,    161.02620276,    204.33597179,\n",
       "          259.29437974,    329.03445623,    417.53189366,    529.83169063,\n",
       "          672.33575365,    853.16785242,   1082.63673387,   1373.82379588,\n",
       "         1743.3288222 ,   2212.21629107,   2807.21620394,   3562.24789026,\n",
       "         4520.35365636,   5736.15251045,   7278.95384398,   9236.70857187,\n",
       "        11721.02297533,  14873.52107294,  18873.91822135,  23950.26619987,\n",
       "        30391.95382313,  38566.20421163,  48939.00918477,  62101.69418916,\n",
       "        78804.6281567 , 100000.        ])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign the best model with the best parameter \n",
    "svm_rbf_reg = grid_search_rbf.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Candidate Model 1 Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The naive RMSE baseline is  71.64007462993281\n",
      "The regression_baseline is  71.65740368288068\n",
      "The model performance in training is  52.72247520029191\n",
      "The model performance in testing is  58.4375534668241\n"
     ]
    }
   ],
   "source": [
    "# compare results dummy and naive regressor.\n",
    "results(svm_rbf_reg, X_train, X_test, y_train, y_test )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2 Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_reg_poly = SVR(kernel='poly')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2 results before hyperparameters tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The naive RMSE baseline is  71.64007462993281\n",
      "The regression_baseline is  71.65740368288068\n",
      "The model performance in training is  66.43206643624907\n",
      "The model performance in testing is  65.32834481110129\n"
     ]
    }
   ],
   "source": [
    "svm_reg_poly.fit(X_train, y_train)\n",
    "\n",
    "results(svm_reg_poly, X_train, X_test, y_train, y_test )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2 Training and Hyperparameter Tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 90000 candidates, totalling 450000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0122s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0890s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  50 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  72 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0744s.) Setting batch_size=8.\n",
      "[Parallel(n_jobs=-1)]: Done 124 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0968s.) Setting batch_size=16.\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 304 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0848s.) Setting batch_size=32.\n",
      "[Parallel(n_jobs=-1)]: Done 488 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1320 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1928 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done 2536 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done 3208 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done 3880 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done 4616 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done 5352 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done 6152 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done 6952 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=-1)]: Done 7816 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Done 8680 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=-1)]: Done 9608 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=-1)]: Done 10536 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=-1)]: Done 11528 tasks      | elapsed:    7.4s\n",
      "[Parallel(n_jobs=-1)]: Done 12520 tasks      | elapsed:    8.0s\n",
      "[Parallel(n_jobs=-1)]: Done 13576 tasks      | elapsed:    8.7s\n",
      "[Parallel(n_jobs=-1)]: Done 14632 tasks      | elapsed:    9.5s\n",
      "[Parallel(n_jobs=-1)]: Done 15752 tasks      | elapsed:   10.1s\n",
      "[Parallel(n_jobs=-1)]: Done 16872 tasks      | elapsed:   10.8s\n",
      "[Parallel(n_jobs=-1)]: Done 18056 tasks      | elapsed:   11.5s\n",
      "[Parallel(n_jobs=-1)]: Done 19240 tasks      | elapsed:   12.4s\n",
      "[Parallel(n_jobs=-1)]: Done 20488 tasks      | elapsed:   13.1s\n",
      "[Parallel(n_jobs=-1)]: Done 21736 tasks      | elapsed:   13.8s\n",
      "[Parallel(n_jobs=-1)]: Done 23048 tasks      | elapsed:   14.6s\n",
      "[Parallel(n_jobs=-1)]: Done 24360 tasks      | elapsed:   15.5s\n",
      "[Parallel(n_jobs=-1)]: Done 25736 tasks      | elapsed:   16.3s\n",
      "[Parallel(n_jobs=-1)]: Done 27112 tasks      | elapsed:   17.2s\n",
      "[Parallel(n_jobs=-1)]: Done 28552 tasks      | elapsed:   18.1s\n",
      "[Parallel(n_jobs=-1)]: Done 29992 tasks      | elapsed:   19.1s\n",
      "[Parallel(n_jobs=-1)]: Done 31496 tasks      | elapsed:   19.9s\n",
      "[Parallel(n_jobs=-1)]: Done 33000 tasks      | elapsed:   20.9s\n",
      "[Parallel(n_jobs=-1)]: Done 34568 tasks      | elapsed:   21.8s\n",
      "[Parallel(n_jobs=-1)]: Done 36136 tasks      | elapsed:   22.9s\n",
      "[Parallel(n_jobs=-1)]: Done 37768 tasks      | elapsed:   23.9s\n",
      "[Parallel(n_jobs=-1)]: Done 39400 tasks      | elapsed:   24.9s\n",
      "[Parallel(n_jobs=-1)]: Done 41096 tasks      | elapsed:   25.9s\n",
      "[Parallel(n_jobs=-1)]: Done 42792 tasks      | elapsed:   27.1s\n",
      "[Parallel(n_jobs=-1)]: Done 44552 tasks      | elapsed:   28.1s\n",
      "[Parallel(n_jobs=-1)]: Done 46312 tasks      | elapsed:   29.2s\n",
      "[Parallel(n_jobs=-1)]: Done 48136 tasks      | elapsed:   30.4s\n",
      "[Parallel(n_jobs=-1)]: Done 49960 tasks      | elapsed:   31.6s\n",
      "[Parallel(n_jobs=-1)]: Done 51848 tasks      | elapsed:   32.7s\n",
      "[Parallel(n_jobs=-1)]: Done 53736 tasks      | elapsed:   33.8s\n",
      "[Parallel(n_jobs=-1)]: Done 55688 tasks      | elapsed:   35.1s\n",
      "[Parallel(n_jobs=-1)]: Done 57640 tasks      | elapsed:   36.4s\n",
      "[Parallel(n_jobs=-1)]: Done 59656 tasks      | elapsed:   37.6s\n",
      "[Parallel(n_jobs=-1)]: Done 61672 tasks      | elapsed:   38.8s\n",
      "[Parallel(n_jobs=-1)]: Done 63752 tasks      | elapsed:   40.1s\n",
      "[Parallel(n_jobs=-1)]: Done 65832 tasks      | elapsed:   41.5s\n",
      "[Parallel(n_jobs=-1)]: Done 67976 tasks      | elapsed:   42.8s\n",
      "[Parallel(n_jobs=-1)]: Done 70120 tasks      | elapsed:   44.2s\n",
      "[Parallel(n_jobs=-1)]: Done 72328 tasks      | elapsed:   45.6s\n",
      "[Parallel(n_jobs=-1)]: Done 74536 tasks      | elapsed:   47.1s\n",
      "[Parallel(n_jobs=-1)]: Done 76808 tasks      | elapsed:   48.3s\n",
      "[Parallel(n_jobs=-1)]: Done 79080 tasks      | elapsed:   49.7s\n",
      "[Parallel(n_jobs=-1)]: Done 81416 tasks      | elapsed:   51.2s\n",
      "[Parallel(n_jobs=-1)]: Done 83752 tasks      | elapsed:   52.8s\n",
      "[Parallel(n_jobs=-1)]: Done 86152 tasks      | elapsed:   54.2s\n",
      "[Parallel(n_jobs=-1)]: Done 88552 tasks      | elapsed:   55.8s\n",
      "[Parallel(n_jobs=-1)]: Done 91016 tasks      | elapsed:   57.3s\n",
      "[Parallel(n_jobs=-1)]: Done 93480 tasks      | elapsed:   58.8s\n",
      "[Parallel(n_jobs=-1)]: Done 96008 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 98536 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 101128 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 103720 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 106376 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 109032 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 111752 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 114472 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 117256 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 120040 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 122888 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 125736 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 128648 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 131560 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 134536 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 137512 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 140552 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 143592 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 146696 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 149800 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 152968 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 156136 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 159368 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 162600 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 165896 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 169192 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 172552 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 175912 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 179336 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 182760 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 186248 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 189736 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 193288 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 196840 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 200456 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 204072 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 207752 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 211432 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 215176 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 218920 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 222728 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 226536 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 230408 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 234280 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 238216 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 242152 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 246152 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 250152 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 254216 tasks      | elapsed:  2.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 258280 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 262408 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 266536 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 270728 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 274920 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 279176 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 283432 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 287752 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 292072 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 296456 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 300840 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 305288 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 309736 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 314248 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 318760 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 323336 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 327912 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 332552 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 337192 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 341896 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 346600 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 351368 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 356136 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 360968 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 365800 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done 370696 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done 375592 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done 380552 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 385512 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 390536 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=-1)]: Done 395560 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=-1)]: Done 400648 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=-1)]: Done 405736 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=-1)]: Done 410888 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=-1)]: Done 416040 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=-1)]: Done 421256 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=-1)]: Done 426472 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-1)]: Done 431752 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-1)]: Done 437032 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=-1)]: Done 442376 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=-1)]: Done 447720 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=-1)]: Done 450000 out of 450000 | elapsed:  4.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 7278.953843983146,\n",
       " 'degree': 1,\n",
       " 'epsilon': 0.1,\n",
       " 'gamma': 0.07847599703514611}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#######################################\n",
    "# hyperparameter ranges \n",
    "C_range = np.logspace(2, 5 , 30)\n",
    "gamma_range = np.logspace(-3, -1, 20)\n",
    "epsilon_range = np.linspace(0.1,0.9)\n",
    "degree_range = list(range(1,4))\n",
    "\n",
    "#######################################\n",
    "param_grid = dict(gamma=gamma_range, C=C_range, epsilon=epsilon_range, degree=degree_range)\n",
    "\n",
    "\n",
    "grid_search_poly = GridSearchCV(svm_reg_poly, param_grid, n_jobs=-1, verbose=10,\n",
    "                                        cv=5, scoring=\"neg_root_mean_squared_error\")\n",
    "    \n",
    "# initialize gridsearch    \n",
    "grid_search_poly.fit(X_train,y_train)\n",
    "grid_search_poly.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign the best model with the best parameter \n",
    "svm_poly_reg = grid_search_poly.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Candidate Model 2 Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The naive RMSE baseline is  71.64007462993281\n",
      "The regression_baseline is  71.65740368288068\n",
      "The model performance in training is  52.78348641564139\n",
      "The model performance in testing is  58.49944180775057\n"
     ]
    }
   ],
   "source": [
    "# compare results dummy and naive regressor.\n",
    "results(svm_poly_reg, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
